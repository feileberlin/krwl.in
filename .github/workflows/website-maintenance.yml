name: ü§ñ Event Scraping, Weather Updates & Site Deployment

# Comprehensive automation workflow for the KRWL HOF community events site
# Handles: event scraping from RSS/HTML sources, weather updates, HTML generation, 
# editorial workflow (review/publish), event archiving, and GitHub Pages deployment
# This workflow dynamically adapts to scraper configuration changes

on:
  schedule:
    # Dynamic scheduling based on config.json scraping.schedule
    # These times are read from scraper capabilities at runtime
    # Default: 04:00 and 16:00 Europe/Berlin (03:00 and 15:00 UTC)
    - cron: '0 3 * * *'   # 4:00 AM Berlin time (CET)
    - cron: '0 15 * * *'  # 4:00 PM Berlin time (CET)
  
  push:
    branches:
      - main
    paths:
      - 'assets/json/events.json'       # Published events data
      - 'assets/json/events.demo.json'  # Demo events data
      - 'config.json'                   # Configuration changes
      - 'src/modules/scraper.py'        # Scraper changes trigger workflow update
  
  # Telegram bot integration via repository_dispatch
  repository_dispatch:
    types:
      - telegram_flyer_submission    # Flyer upload for OCR processing
      - telegram_contact_submission  # Contact form message
      - telegram_pin_submission      # PIN publishing by trusted organizer
  
  workflow_dispatch:  # Manual trigger with comprehensive task options
    inputs:
      task:
        description: 'üéØ Action to perform - Select the maintenance task you want to execute'
        required: true
        type: choice
        options:
          - 'scrape-only'        # Scrape events from RSS/HTML sources without deployment
          - 'scrape-and-deploy'  # Scrape new events and automatically deploy changes to production
          - 'force-deploy'       # Force complete site rebuild and deployment (ignores cache)
          - 'update-events'      # Fast path: Update event data in HTML without full rebuild
          - 'review-pending'     # Editorial workflow: Review and publish pending events awaiting approval
          - 'scrape-weather'     # Fetch current weather and clothing recommendations for map location
          - 'info'               # Display scraper configuration and capabilities (diagnostic tool)
          - 'process-telegram-flyer'    # Process Telegram flyer submission with OCR
          - 'process-telegram-contact'  # Process Telegram contact form submission
          - 'process-telegram-pin'      # Process Telegram PIN publishing submission
        default: 'scrape-and-deploy'
      
      force_scrape:
        description: 'üîÑ Force scraping even if source URLs have not changed since last run'
        type: boolean
        default: false
      
      # Editorial workflow options (used with 'review-pending' task)
      event_ids:
        description: 'üìù Event IDs to publish - Comma-separated list (e.g., "pending_123,pending_456") or "all" for bulk approval'
        type: string
        required: false
      
      auto_publish_pattern:
        description: 'üîç Auto-publish events matching glob pattern - Example: "pending_*" publishes all pending events automatically'
        type: string
        required: false
      
      # Telegram processing options (used with process-telegram-* tasks)
      telegram_file_id:
        description: 'üìÅ Telegram file ID for flyer processing'
        type: string
        required: false
      
      telegram_message:
        description: 'üí¨ Telegram contact message text'
        type: string
        required: false
      
      telegram_user_id:
        description: 'üë§ Telegram user ID'
        type: string
        required: false
      
      telegram_pin:
        description: 'üîê 4-digit PIN for trusted organizer publishing'
        type: string
        required: false
      
      telegram_event_json:
        description: 'üìã Event JSON data for PIN publishing'
        type: string
        required: false

permissions:
  contents: write
  pages: write
  id-token: write
  issues: write

# Prevent concurrent runs to avoid conflicts
concurrency:
  group: "website-maintenance"
  cancel-in-progress: false

jobs:
  # Job 1: Introspect scraper capabilities and configuration
  discover-capabilities:
    name: üîç Discover Scraper Configuration & Capabilities
    runs-on: ubuntu-latest
    outputs:
      capabilities: ${{ steps.introspect.outputs.capabilities }}
      enabled_sources: ${{ steps.introspect.outputs.enabled_sources }}
      source_count: ${{ steps.introspect.outputs.source_count }}
      scraping_enabled: ${{ steps.introspect.outputs.scraping_enabled }}
      schedule_timezone: ${{ steps.introspect.outputs.schedule_timezone }}
      schedule_times: ${{ steps.introspect.outputs.schedule_times }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Introspect scraper capabilities
        id: introspect
        run: |
          set -e  # Exit on error
          
          echo "üîç Discovering scraper capabilities..."
          
          # Get scraper capabilities via CLI with --json flag for clean output
          # The --json flag suppresses all logging to ensure pure JSON
          if ! CAPABILITIES=$(python3 src/event_manager.py scraper-info --json); then
            echo "‚ùå Error: scraper-info command failed"
            echo "Exit code: $?"
            exit 1
          fi
          
          # Validate JSON before proceeding
          if ! echo "$CAPABILITIES" | jq empty 2>/dev/null; then
            echo "‚ùå Error: scraper-info did not output valid JSON"
            echo "Raw output:"
            echo "$CAPABILITIES"
            echo ""
            echo "Attempting to extract JSON from output..."
            # Try to extract JSON from mixed output (fallback)
            CAPABILITIES=$(echo "$CAPABILITIES" | sed -n '/^{/,$p')
            if ! echo "$CAPABILITIES" | jq empty 2>/dev/null; then
              echo "‚ùå Could not extract valid JSON. Using safe defaults."
              # Use safe fallback values
              echo "enabled_sources=0" >> $GITHUB_OUTPUT
              echo "source_count=0" >> $GITHUB_OUTPUT
              echo "scraping_enabled=false" >> $GITHUB_OUTPUT
              echo "schedule_timezone=Europe/Berlin" >> $GITHUB_OUTPUT
              echo "schedule_times=04:00, 16:00" >> $GITHUB_OUTPUT
              echo "capabilities={}" >> $GITHUB_OUTPUT
              exit 0  # Don't fail the whole workflow
            fi
          fi
          
          # Store capabilities for other jobs
          echo "capabilities<<EOF" >> $GITHUB_OUTPUT
          echo "$CAPABILITIES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          # Extract specific fields for conditional logic with error handling
          ENABLED_SOURCES=$(echo "$CAPABILITIES" | jq -r '.enabled_sources | length' 2>/dev/null || echo "0")
          SCRAPING_ENABLED=$(echo "$CAPABILITIES" | jq -r '.scraping_libraries_installed' 2>/dev/null || echo "false")
          SCHEDULE_TZ=$(echo "$CAPABILITIES" | jq -r '.schedule.timezone // "Europe/Berlin"' 2>/dev/null)
          SCHEDULE_TIMES=$(echo "$CAPABILITIES" | jq -r '.schedule.times | join(", ")' 2>/dev/null || echo "04:00, 16:00")
          
          echo "enabled_sources=$ENABLED_SOURCES" >> $GITHUB_OUTPUT
          echo "source_count=$ENABLED_SOURCES" >> $GITHUB_OUTPUT
          echo "scraping_enabled=$SCRAPING_ENABLED" >> $GITHUB_OUTPUT
          echo "schedule_timezone=$SCHEDULE_TZ" >> $GITHUB_OUTPUT
          echo "schedule_times=$SCHEDULE_TIMES" >> $GITHUB_OUTPUT
          
          echo "‚úì Scraper capabilities discovered"
          echo "  - Enabled sources: $ENABLED_SOURCES"
          echo "  - Scraping enabled: $SCRAPING_ENABLED"
          echo "  - Schedule: $SCHEDULE_TIMES ($SCHEDULE_TZ)"
      
      - name: Display capabilities
        run: |
          echo "## üîç Scraper Capabilities" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          echo '${{ steps.introspect.outputs.capabilities }}' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

  # Job 2: Scrape community events from configured RSS/HTML sources
  scrape-events:
    name: üìÖ Scrape Community Events from RSS & HTML Sources
    runs-on: ubuntu-latest
    needs: discover-capabilities
    if: |
      (github.event_name == 'schedule' || 
       github.event.inputs.task == 'scrape-only' || 
       github.event.inputs.task == 'scrape-and-deploy' ||
       github.event.inputs.force_scrape == 'true') &&
      needs.discover-capabilities.outputs.scraping_enabled == 'true' &&
      needs.discover-capabilities.outputs.source_count != '0'
    
    outputs:
      changes_detected: ${{ steps.check_changes.outputs.changes_detected }}
      pending_count: ${{ steps.count_pending.outputs.pending_count }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Configure Git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
      
      - name: Run scraper (adaptive)
        id: scrape
        run: |
          echo "üîç Starting event scraping..."
          echo "Scraping from ${{ needs.discover-capabilities.outputs.source_count }} enabled sources"
          
          # Run scraper using event_manager CLI
          python3 src/event_manager.py scrape
          
          echo "‚úì Scraping completed"
      
      - name: Check for changes
        id: check_changes
        run: |
          if [[ -n $(git status --porcelain assets/json/) ]]; then
            echo "changes_detected=true" >> $GITHUB_OUTPUT
            echo "‚úì New events detected"
          else
            echo "changes_detected=false" >> $GITHUB_OUTPUT
            echo "‚Ñπ No new events found"
          fi
      
      - name: Count pending events
        id: count_pending
        run: |
          if [ -f assets/json/pending_events.json ]; then
            COUNT=$(python3 -c "import json; data = json.load(open('assets/json/pending_events.json')); print(len(data.get('pending_events', [])))")
            echo "pending_count=$COUNT" >> $GITHUB_OUTPUT
            echo "‚Ñπ Pending events: $COUNT"
          else
            echo "pending_count=0" >> $GITHUB_OUTPUT
            echo "‚Ñπ Pending events: 0"
          fi
      
      - name: Commit and push changes
        if: steps.check_changes.outputs.changes_detected == 'true'
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M UTC')
          git add assets/json/
          git commit -m "chore: automated event scraping - $TIMESTAMP"
          
          # Pull with rebase to handle concurrent changes
          if ! git pull --rebase origin main; then
            echo "‚ùå Rebase failed - manual intervention required"
            git rebase --abort || true
            exit 1
          fi
          
          git push
          echo "‚úì Changes committed and pushed"
      
      - name: Generate scraping summary
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
          PENDING_COUNT="${{ steps.count_pending.outputs.pending_count }}"
          CHANGES="${{ steps.check_changes.outputs.changes_detected }}"
          
          echo "## üîç Event Scraping Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Date/Time:** $TIMESTAMP" >> $GITHUB_STEP_SUMMARY
          echo "**Sources:** ${{ needs.discover-capabilities.outputs.source_count }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$CHANGES" == "true" ]; then
            echo "**Status:** ‚úÖ New events found" >> $GITHUB_STEP_SUMMARY
          else
            echo "**Status:** ‚ÑπÔ∏è No new events" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "**Pending Events:** $PENDING_COUNT" >> $GITHUB_STEP_SUMMARY
          
          if [ "$PENDING_COUNT" -gt "0" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "‚ö†Ô∏è **Action Required:** $PENDING_COUNT events awaiting review" >> $GITHUB_STEP_SUMMARY
          fi

  # Job 2.5: Scrape current weather and generate clothing recommendations
  scrape-weather:
    name: üå§Ô∏è Scrape Weather Data & Clothing Recommendations
    runs-on: ubuntu-latest
    needs: discover-capabilities
    if: |
      github.event_name == 'schedule' ||
      github.event.inputs.task == 'scrape-weather' ||
      github.event.inputs.task == 'scrape-and-deploy'
    
    outputs:
      weather_scraped: ${{ steps.scrape_weather.outputs.weather_scraped }}
      artifact_uploaded: ${{ steps.set_artifact_uploaded_output.outputs.artifact_uploaded }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Configure Git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
      
      - name: Run weather scraper
        id: scrape_weather
        run: |
          echo "üå§Ô∏è Scraping weather and dresscode..."
          
          # Run weather scraper using event_manager CLI
          if python3 src/event_manager.py scrape-weather; then
            echo "weather_scraped=true" >> $GITHUB_OUTPUT
            echo "‚úì Weather scraping completed"
          else
            echo "weather_scraped=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è Weather scraping failed (non-critical)"
          fi
      
      - name: Check for changes
        id: check_changes
        run: |
          if [[ -n $(git status --porcelain assets/json/weather_cache.json) ]]; then
            echo "changes_detected=true" >> $GITHUB_OUTPUT
            echo "‚úì Weather cache updated"
          else
            echo "changes_detected=false" >> $GITHUB_OUTPUT
            echo "‚Ñπ No weather changes"
          fi
      
      - name: Update weather in HTML (fast update, no rebuild)
        if: steps.check_changes.outputs.changes_detected == 'true'
        run: |
          echo "‚ö° Updating weather data in HTML without full rebuild..."
          
          # Fast update: inject weather data into existing HTML
          if python3 src/event_manager.py update-weather; then
            echo "‚úì Weather data updated in HTML"
          else
            echo "‚ö†Ô∏è Weather update in HTML failed (will need full rebuild)"
          fi
      
      - name: Commit and push weather cache and HTML
        if: steps.check_changes.outputs.changes_detected == 'true'
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M UTC')
          git add assets/json/weather_cache.json public/index.html
          git commit -m "chore: update weather data - $TIMESTAMP [skip ci]"
          
          # Pull with rebase to handle concurrent changes
          if ! git pull --rebase origin main; then
            echo "‚ùå Rebase failed - manual intervention required"
            git rebase --abort || true
            exit 1
          fi
          
          git push
          echo "‚úì Weather cache and HTML committed and pushed"
      
      - name: Generate weather summary
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
          WEATHER_SCRAPED="${{ steps.scrape_weather.outputs.weather_scraped }}"
          
          echo "## üå§Ô∏è Weather Scraping Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Date/Time:** $TIMESTAMP" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$WEATHER_SCRAPED" == "true" ]; then
            echo "**Status:** ‚úÖ Weather scraped successfully" >> $GITHUB_STEP_SUMMARY
            
            # Display weather data if available
            if [ -f assets/json/weather_cache.json ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "**Weather Data:**" >> $GITHUB_STEP_SUMMARY
              echo '```json' >> $GITHUB_STEP_SUMMARY
              cat assets/json/weather_cache.json >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "**Status:** ‚ö†Ô∏è Weather scraping failed" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Upload artifact (fast weather update)
        id: upload_artifact
        if: steps.check_changes.outputs.changes_detected == 'true'
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./public
      
      - name: Set artifact uploaded output
        if: steps.check_changes.outputs.changes_detected == 'true'
        run: |
          echo "artifact_uploaded=true" >> $GITHUB_OUTPUT

  # Job 3: Fast path to update event data without full site rebuild
  update-events:
    name: ‚ö° Fast Event Data Update (No Rebuild)
    runs-on: ubuntu-latest
    needs: [discover-capabilities, scrape-events, scrape-weather]
    if: |
      always() &&
      (github.event.inputs.task == 'update-events' ||
       (github.event_name == 'push' && 
        contains(github.event.head_commit.modified, 'assets/json/events.json')))
    
    outputs:
      artifact_uploaded: ${{ steps.upload_artifact.outputs.artifact_uploaded }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Fast update events data
        run: |
          echo "‚ö° Fast updating events data..."
          python3 src/event_manager.py update
          echo "‚úì Events data updated"
      
      - name: Upload artifact
        id: upload_artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./public
      
      - name: Set artifact uploaded output
        run: |
          echo "artifact_uploaded=true" >> $GITHUB_OUTPUT

  # Job 4: Complete site rebuild from source files (CSS, JS, HTML components)
  full-rebuild:
    name: üî® Full Site Rebuild & HTML Generation
    runs-on: ubuntu-latest
    needs: [discover-capabilities, scrape-events, scrape-weather]
    if: |
      always() &&
      (github.event.inputs.task == 'force-deploy' ||
       github.event.inputs.task == 'scrape-and-deploy' ||
       (github.event_name == 'push' && 
        (contains(github.event.head_commit.modified, 'config.json') ||
         contains(github.event.head_commit.modified, 'src/modules/scraper.py'))))
    
    outputs:
      artifact_uploaded: ${{ steps.upload_artifact.outputs.artifact_uploaded }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Fetch third-party dependencies
        run: |
          echo "üì¶ Fetching dependencies..."
          python3 src/event_manager.py dependencies fetch
      
      - name: Verify dependencies
        run: |
          python3 src/event_manager.py dependencies check
      
      - name: Full site generation
        run: |
          echo "üî® Building site..."
          python3 src/event_manager.py generate
          echo "‚úì Site built successfully"
      
      - name: Add deployment timestamp
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
          if [ -f public/index.html ]; then
            sed -i "s/BUILD_TIMESTAMP_PLACEHOLDER/$TIMESTAMP/g" public/index.html
          fi
      
      - name: Upload artifact
        id: upload_artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./public
      
      - name: Set artifact uploaded output
        run: |
          echo "artifact_uploaded=true" >> $GITHUB_OUTPUT

  # Job 5: Deploy compiled site to GitHub Pages hosting
  deploy:
    name: üöÄ Deploy to GitHub Pages Production
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: [update-events, full-rebuild, scrape-weather]
    if: |
      always() &&
      (needs.update-events.outputs.artifact_uploaded == 'true' || 
       needs.full-rebuild.outputs.artifact_uploaded == 'true' ||
       needs.scrape-weather.outputs.artifact_uploaded == 'true')
    
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
      
      - name: Deployment summary
        run: |
          echo "## üöÄ Deployment Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**URL:** ${{ steps.deployment.outputs.page_url }}" >> $GITHUB_STEP_SUMMARY
          echo "**Time:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY

  # Job 6: Display scraper configuration and diagnostic information
  show-info:
    name: üìä Display Scraper Configuration & Diagnostics
    runs-on: ubuntu-latest
    needs: discover-capabilities
    if: github.event.inputs.task == 'info'
    
    steps:
      - name: Display full capabilities
        run: |
          echo "## üîç Complete Scraper Capabilities" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          echo '${{ needs.discover-capabilities.outputs.capabilities }}' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Key Information" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Enabled Sources:** ${{ needs.discover-capabilities.outputs.source_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Scraping Libraries:** ${{ needs.discover-capabilities.outputs.scraping_enabled }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Schedule:** ${{ needs.discover-capabilities.outputs.schedule_times }} (${{ needs.discover-capabilities.outputs.schedule_timezone }})" >> $GITHUB_STEP_SUMMARY

  # Job 7: Editorial workflow to review and publish pending events
  review-pending:
    name: ‚úèÔ∏è Editorial Review & Publish Pending Events
    runs-on: ubuntu-latest
    needs: discover-capabilities
    if: |
      github.event.inputs.task == 'review-pending' ||
      (github.event.inputs.auto_publish_pattern != '' && github.event.inputs.auto_publish_pattern != null)
    
    outputs:
      published_count: ${{ steps.publish.outputs.published_count }}
      events_published: ${{ steps.publish.outputs.events_published }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # Ensure we have latest changes
          ref: main
      
      - name: Pull latest changes
        run: |
          git pull origin main
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Configure Git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
      
      - name: List pending events
        id: list_pending
        run: |
          echo "üìã Listing pending events..."
          
          # List pending events (if list-pending command exists)
          if python3 src/event_manager.py list-pending > pending_list.txt 2>&1; then
            cat pending_list.txt
          else
            echo "‚ö†Ô∏è  Could not run list-pending command"
          fi
          
          # Count pending events with error handling
          PENDING_COUNT=$(python3 -c "
          import json
          try:
              with open('assets/json/pending_events.json', 'r') as f:
                  data = json.load(f)
              print(len(data.get('pending_events', [])))
          except (FileNotFoundError, json.JSONDecodeError, KeyError) as e:
              print('0')
          " 2>/dev/null)
          
          # Validate the count is a valid number, default to 0 if not
          if [[ -z "$PENDING_COUNT" || ! "$PENDING_COUNT" =~ ^[0-9]+$ ]]; then
            PENDING_COUNT=0
          fi
          
          echo "pending_count=${PENDING_COUNT}" >> "$GITHUB_OUTPUT"
          echo "‚Ñπ Found $PENDING_COUNT pending events"
          
          # Add to summary
          echo "## üìã Pending Events Review" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Pending Events:** $PENDING_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$PENDING_COUNT" -gt 0 ]; then
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat pending_list.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ÑπÔ∏è No pending events to review." >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Publish events (auto or manual)
        id: publish
        run: |
          echo "üîÑ Publishing events..."
          PUBLISHED_COUNT=0
          PUBLISHED_IDS=""
          
          # Check for auto-publish pattern
          AUTO_PATTERN="${{ github.event.inputs.auto_publish_pattern }}"
          MANUAL_IDS="${{ github.event.inputs.event_ids }}"
          
          if [ -n "$AUTO_PATTERN" ]; then
            echo "üì¶ Auto-publishing events matching: $AUTO_PATTERN"
            
            # Use bulk-publish with pattern
            if python3 src/event_manager.py bulk-publish "$AUTO_PATTERN"; then
              # Count how many were published
              PUBLISHED_COUNT=$(git diff --cached --name-only | grep -c "events.json" || echo "0")
              PUBLISHED_IDS="Pattern: $AUTO_PATTERN"
              echo "‚úì Auto-published events matching pattern"
            else
              echo "‚ö†Ô∏è Auto-publish failed or no events matched pattern"
            fi
            
          elif [ -n "$MANUAL_IDS" ]; then
            echo "üìù Publishing specific events: $MANUAL_IDS"
            
            if [ "$MANUAL_IDS" = "all" ]; then
              # Publish all pending events
              echo "Publishing ALL pending events..."
              python3 src/event_manager.py bulk-publish "pending_*"
              PUBLISHED_COUNT=$(git diff --cached --name-only | grep -c "events.json" || echo "0")
              PUBLISHED_IDS="all"
            else
              # Publish specific IDs (comma-separated)
              IFS=',' read -ra IDS_ARRAY <<< "$MANUAL_IDS"
              for EVENT_ID in "${IDS_ARRAY[@]}"; do
                EVENT_ID=$(echo "$EVENT_ID" | xargs)  # Trim whitespace
                echo "Publishing: $EVENT_ID"
                if python3 src/event_manager.py publish "$EVENT_ID"; then
                  PUBLISHED_COUNT=$((PUBLISHED_COUNT + 1))
                  PUBLISHED_IDS="$PUBLISHED_IDS $EVENT_ID"
                else
                  echo "‚ö†Ô∏è Failed to publish: $EVENT_ID"
                fi
              done
            fi
            
          else
            echo "‚ö†Ô∏è No events specified for publishing"
            echo "Provide either 'event_ids' or 'auto_publish_pattern'"
          fi
          
          echo "published_count=$PUBLISHED_COUNT" >> $GITHUB_OUTPUT
          echo "events_published=$PUBLISHED_IDS" >> $GITHUB_OUTPUT
          
          echo "‚úì Published $PUBLISHED_COUNT event(s)"
          
          # Add to summary
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Publishing Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Published:** $PUBLISHED_COUNT event(s)" >> $GITHUB_STEP_SUMMARY
          if [ -n "$PUBLISHED_IDS" ]; then
            echo "- **IDs:** $PUBLISHED_IDS" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Commit and push changes
        if: steps.publish.outputs.published_count != '0'
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M UTC')
          PUBLISHED_COUNT="${{ steps.publish.outputs.published_count }}"
          
          git add assets/json/
          git commit -m "chore: publish $PUBLISHED_COUNT event(s) - $TIMESTAMP"
          
          # Pull with rebase to handle concurrent changes
          if ! git pull --rebase origin main; then
            echo "‚ùå Rebase failed - manual intervention required"
            git rebase --abort || true
            exit 1
          fi
          
          git push
          echo "‚úì Changes committed and pushed"
      
      - name: Trigger deployment
        if: steps.publish.outputs.published_count != '0'
        run: |
          echo "üöÄ Events published, deployment will be triggered automatically"
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ **Deployment triggered automatically** (push to events.json)" >> $GITHUB_STEP_SUMMARY
  
  # Job 8: Monthly archiving of past events to keep active list manageable
  archive-monthly:
    name: üóÑÔ∏è Archive Past Events (Monthly Maintenance)
    runs-on: ubuntu-latest
    # Run only on schedule (first day of month) or manual trigger
    if: |
      github.event_name == 'schedule' ||
      github.event.inputs.task == 'archive-monthly'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Read archiving configuration
        id: config
        run: |
          echo "üìã Reading archiving configuration from config.json..."
          
          # Extract archiving config
          ENABLED=$(jq -r '.archiving.enabled // true' config.json)
          RETENTION_DAYS=$(jq -r '.archiving.retention.active_window_days // 60' config.json)
          SCHEDULE_DAY=$(jq -r '.archiving.schedule.day_of_month // 1' config.json)
          SCHEDULE_TIME=$(jq -r '.archiving.schedule.time // "02:00"' config.json)
          
          echo "enabled=$ENABLED" >> $GITHUB_OUTPUT
          echo "retention_days=$RETENTION_DAYS" >> $GITHUB_OUTPUT
          echo "schedule_day=$SCHEDULE_DAY" >> $GITHUB_OUTPUT
          echo "schedule_time=$SCHEDULE_TIME" >> $GITHUB_OUTPUT
          
          echo "‚úì Archiving config:"
          echo "  - Enabled: $ENABLED"
          echo "  - Retention: $RETENTION_DAYS days"
          echo "  - Schedule: Day $SCHEDULE_DAY at $SCHEDULE_TIME UTC"
      
      - name: Display configuration
        run: |
          echo "## üóÑÔ∏è Archiving Configuration" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Enabled:** ${{ steps.config.outputs.enabled }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Retention:** ${{ steps.config.outputs.retention_days }} days" >> $GITHUB_STEP_SUMMARY
          echo "- **Schedule:** Day ${{ steps.config.outputs.schedule_day }} at ${{ steps.config.outputs.schedule_time }} UTC" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
      
      - name: Run archiving (dry-run first)
        id: dry_run
        run: |
          echo "üîç Running dry-run to preview archiving..."
          python3 src/event_manager.py archive-monthly --dry-run | tee dry_run_output.txt
          
          # Extract results
          ARCHIVED_COUNT=$(grep "Would archive:" dry_run_output.txt | awk '{print $3}' || echo "0")
          ACTIVE_COUNT=$(grep "Remaining active:" dry_run_output.txt | awk '{print $3}' || echo "0")
          
          echo "archived_count=$ARCHIVED_COUNT" >> $GITHUB_OUTPUT
          echo "active_count=$ACTIVE_COUNT" >> $GITHUB_OUTPUT
          
          echo "‚úì Dry-run complete:"
          echo "  - Would archive: $ARCHIVED_COUNT events"
          echo "  - Would remain active: $ACTIVE_COUNT events"
      
      - name: Display dry-run results
        run: |
          echo "### üîç Dry-Run Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Would archive:** ${{ steps.dry_run.outputs.archived_count }} events" >> $GITHUB_STEP_SUMMARY
          echo "- **Would remain active:** ${{ steps.dry_run.outputs.active_count }} events" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
      
      - name: Run actual archiving
        id: archive
        if: |
          steps.config.outputs.enabled == 'true' &&
          steps.dry_run.outputs.archived_count != '0'
        run: |
          echo "üóÑÔ∏è Running actual archiving..."
          python3 src/event_manager.py archive-monthly | tee archive_output.txt
          
          # Extract results
          ARCHIVED_COUNT=$(grep "Archived:" archive_output.txt | awk '{print $2}' || echo "0")
          
          echo "archived_count=$ARCHIVED_COUNT" >> $GITHUB_OUTPUT
          echo "archiving_done=true" >> $GITHUB_OUTPUT
          
          echo "‚úì Archiving complete: $ARCHIVED_COUNT events archived"
      
      - name: Display archiving results
        if: steps.archive.outputs.archiving_done == 'true'
        run: |
          echo "### ‚úÖ Archiving Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Archived:** ${{ steps.archive.outputs.archived_count }} events" >> $GITHUB_STEP_SUMMARY
          echo "- **Archive location:** \`assets/json/events/archived/\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
      
      - name: Commit archived events
        if: steps.archive.outputs.archiving_done == 'true'
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M UTC')
          ARCHIVED_COUNT="${{ steps.archive.outputs.archived_count }}"
          
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          git add assets/json/events/
          git add assets/json/events.json
          git commit -m "chore: archive $ARCHIVED_COUNT old event(s) - $TIMESTAMP [automated]"
          
          # Pull with rebase to handle concurrent changes
          if ! git pull --rebase origin main; then
            echo "‚ùå Rebase failed - manual intervention required"
            git rebase --abort || true
            exit 1
          fi
          
          git push
          echo "‚úì Archived events committed and pushed"
      
      - name: No archiving needed
        if: |
          steps.config.outputs.enabled == 'false' ||
          steps.dry_run.outputs.archived_count == '0'
        run: |
          if [ "${{ steps.config.outputs.enabled }}" == "false" ]; then
            echo "‚ÑπÔ∏è Archiving is disabled in config.json"
            echo "---" >> $GITHUB_STEP_SUMMARY
            echo "‚ÑπÔ∏è **Archiving disabled** in config.json" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚úì No events to archive (all within retention window)"
            echo "---" >> $GITHUB_STEP_SUMMARY
            echo "‚úÖ **No archiving needed** - All events within retention window" >> $GITHUB_STEP_SUMMARY
          fi
  
  # Job 9: Process Telegram flyer submission with OCR
  process-telegram-flyer:
    name: üì∏ Process Telegram Flyer Submission
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'repository_dispatch' && github.event.action == 'telegram_flyer_submission' ||
      github.event.inputs.task == 'process-telegram-flyer'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          
          # Install Tesseract OCR
          sudo apt-get update
          sudo apt-get install -y tesseract-ocr tesseract-ocr-deu tesseract-ocr-eng
          
          echo "‚úÖ Dependencies installed"
      
      - name: Download Telegram file
        env:
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
        run: |
          # Get file info from payload or inputs
          if [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            FILE_ID="${{ github.event.client_payload.file_id }}"
            FILE_NAME="${{ github.event.client_payload.file_name }}"
            USER_ID="${{ github.event.client_payload.user_id }}"
            USERNAME="${{ github.event.client_payload.username }}"
            CAPTION="${{ github.event.client_payload.caption }}"
          else
            FILE_ID="${{ github.event.inputs.telegram_file_id }}"
            FILE_NAME=""
            USER_ID="${{ github.event.inputs.telegram_user_id }}"
            USERNAME="manual"
            CAPTION=""
          fi
          
          if [ -z "$FILE_ID" ]; then
            echo "‚ùå No Telegram file_id provided in event payload or inputs."
            exit 1
          fi
          
          echo "USER_ID=$USER_ID" >> $GITHUB_ENV
          echo "USERNAME=$USERNAME" >> $GITHUB_ENV
          echo "CAPTION=$CAPTION" >> $GITHUB_ENV
          
          echo "Fetching flyer for file_id: $FILE_ID from user $USER_ID"
          
          # Ensure cache directory exists
          mkdir -p .cache/telegram
          
          # Use Telegram Bot API to resolve file_path from file_id
          API_URL="https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/getFile?file_id=$FILE_ID"
          FILE_PATH=$(curl -s "$API_URL" | python3 -c 'import sys, json; data = json.load(sys.stdin); print(data.get("result", {}).get("file_path", ""))' 2>/dev/null || echo "")
          
          if [ -z "$FILE_PATH" ]; then
            echo "‚ùå Failed to resolve Telegram file_path for file_id: $FILE_ID"
            exit 1
          fi
          
          # Derive FILE_NAME from Telegram file_path if not explicitly provided
          if [ -z "$FILE_NAME" ]; then
            FILE_NAME="$(basename "$FILE_PATH")"
            echo "Derived FILE_NAME from Telegram file_path: $FILE_NAME"
          fi
          
          # Persist final FILE_NAME for downstream steps
          echo "FILE_NAME=$FILE_NAME" >> $GITHUB_ENV
          
          DOWNLOAD_URL="https://api.telegram.org/file/bot${TELEGRAM_BOT_TOKEN}/$FILE_PATH"
          echo "Downloading Telegram file from: $DOWNLOAD_URL"
          if ! curl -s -L "$DOWNLOAD_URL" -o ".cache/telegram/$FILE_NAME"; then
            echo "‚ùå Failed to download Telegram file to .cache/telegram/$FILE_NAME"
            exit 1
          fi
          
          echo "‚úÖ Telegram file downloaded to .cache/telegram/$FILE_NAME"
      
      - name: Run Tesseract OCR
        id: ocr
        run: |
          # Create cache directory (should already exist from previous step, but ensure it)
          mkdir -p .cache/telegram
          
          # Check if file exists in cache (downloaded from Telegram in previous step)
          if [ ! -f ".cache/telegram/$FILE_NAME" ]; then
            echo "‚ùå File not found at expected location: .cache/telegram/$FILE_NAME"
            echo "This usually indicates a problem resolving or downloading the Telegram file."
            exit 1
          fi
          
          # Run OCR (German + English)
          echo "üîç Running OCR on $FILE_NAME..."
          tesseract ".cache/telegram/$FILE_NAME" ".cache/telegram/ocr_output" -l deu+eng --psm 6
          
          # Read OCR output
          OCR_TEXT=$(cat .cache/telegram/ocr_output.txt 2>/dev/null || echo "")
          
          if [ -z "$OCR_TEXT" ]; then
            echo "‚ö†Ô∏è No text extracted from flyer"
            OCR_TEXT="No text could be extracted"
          fi
          
          echo "‚úÖ OCR completed"
          echo "OCR output preview:"
          echo "$OCR_TEXT" | head -10
          
          # Save OCR text to environment (truncate for GitHub limits)
          echo "OCR_TEXT<<EOF" >> $GITHUB_ENV
          echo "$OCR_TEXT" | head -50 >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV
      
      - name: Create draft event JSON
        id: create_draft
        env:
          USER_ID: ${{ env.USER_ID }}
          USERNAME: ${{ env.USERNAME }}
          FILE_NAME: ${{ env.FILE_NAME }}
          CAPTION: ${{ env.CAPTION }}
          OCR_TEXT: ${{ env.OCR_TEXT }}
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d_%H-%M-%S')
          DRAFT_FILE="assets/json/pending_events_telegram_${USER_ID}_${TIMESTAMP}.json"
          
          # Create draft event with OCR text using environment variables (safer than inline)
          python3 << 'PYCODE'
          import json
          import os
          import sys
          from datetime import datetime
          
          user_id = os.environ.get("USER_ID", "")
          ocr_text = os.environ.get("OCR_TEXT", "")
          username = os.environ.get("USERNAME", "")
          file_name = os.environ.get("FILE_NAME", "")
          caption = os.environ.get("CAPTION", "")
          timestamp = os.environ.get("TIMESTAMP", "")
          
          draft_file = os.environ.get("DRAFT_FILE", "")
          
          draft = {
              'id': f'telegram_flyer_{user_id}_{timestamp}',
              'title': 'Telegram Flyer Submission',
              'description': ocr_text,
              'teaser': 'Event submitted via Telegram flyer upload',
              'location': {
                  'name': 'Hof',
                  'lat': 50.3167,
                  'lon': 11.9167,
                  'address_hidden': True
              },
              'start_time': datetime.now().isoformat(),
              'end_time': None,
              'url': None,
              'source': 'telegram',
              'scraped_at': datetime.now().isoformat(),
              'status': 'pending',
              'category': 'community',
              'metadata': {
                  'telegram_user_id': user_id,
                  'telegram_username': username,
                  'telegram_file_name': file_name,
                  'telegram_caption': caption,
                  'submitted_via': 'telegram_flyer_ocr',
                  'needs_review': True
              }
          }
          
          with open(draft_file, 'w') as f:
              json.dump(draft, f, indent=2)
          
          print(f'Created draft: {draft_file}')
          PYCODE
          
          echo "TIMESTAMP=$TIMESTAMP" >> $GITHUB_ENV
          echo "DRAFT_FILE=$DRAFT_FILE" >> $GITHUB_ENV
          echo "draft_file=$DRAFT_FILE" >> $GITHUB_OUTPUT
          echo "‚úÖ Draft event created: $DRAFT_FILE"
      
      - name: Commit draft event
        run: |
          git config user.name "telegram-bot[bot]"
          git config user.email "telegram-bot[bot]@users.noreply.github.com"
          
          git add "${{ steps.create_draft.outputs.draft_file }}"
          git commit -m "feat: telegram flyer submission from user $USER_ID [needs-review]"
          git push
          
          echo "‚úÖ Draft event committed"
      
      - name: Create GitHub issue
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const draftFile = '${{ steps.create_draft.outputs.draft_file }}';
            const draftData = JSON.parse(fs.readFileSync(draftFile, 'utf8'));
            
            const issue = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üì∏ Telegram Flyer Submission from @${draftData.metadata.telegram_username}`,
              body: `## Telegram Flyer Submission
            
            **User:** @${draftData.metadata.telegram_username} (ID: ${draftData.metadata.telegram_user_id})
            **File:** ${draftData.metadata.telegram_file_name}
            **Caption:** ${draftData.metadata.telegram_caption || 'None'}
            
            ### OCR Extracted Text
            \`\`\`
            ${draftData.description}
            \`\`\`
            
            ### Draft Event File
            - File: \`${draftFile}\`
            - Status: Needs editorial review
            
            ### Next Steps
            1. Review the OCR-extracted text above
            2. Edit the draft JSON file to correct any OCR errors
            3. Add proper event details (title, date, location, etc.)
            4. Publish the event using the editorial workflow
            
            ### Actions
            - To publish: Run workflow with task \`review-pending\`
            - To edit: Modify \`${draftFile}\` directly in repository`,
              labels: ['telegram-submission', 'needs-review', 'flyer']
            });
            
            console.log(`‚úÖ Created issue #${issue.data.number}`);
  
  # Job 10: Process Telegram contact form submission
  process-telegram-contact:
    name: üí¨ Process Telegram Contact Form
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'repository_dispatch' && github.event.action == 'telegram_contact_submission' ||
      github.event.inputs.task == 'process-telegram-contact'
    
    steps:
      - name: Extract message data
        id: extract
        run: |
          if [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            MESSAGE="${{ github.event.client_payload.message }}"
            USER_ID="${{ github.event.client_payload.user_id }}"
            USERNAME="${{ github.event.client_payload.username }}"
            FIRST_NAME="${{ github.event.client_payload.first_name }}"
            LAST_NAME="${{ github.event.client_payload.last_name }}"
          else
            MESSAGE="${{ github.event.inputs.telegram_message }}"
            USER_ID="${{ github.event.inputs.telegram_user_id }}"
            USERNAME="manual"
            FIRST_NAME=""
            LAST_NAME=""
          fi
          
          echo "message=$MESSAGE" >> $GITHUB_OUTPUT
          echo "user_id=$USER_ID" >> $GITHUB_OUTPUT
          echo "username=$USERNAME" >> $GITHUB_OUTPUT
          echo "first_name=$FIRST_NAME" >> $GITHUB_OUTPUT
          echo "last_name=$LAST_NAME" >> $GITHUB_OUTPUT
      
      - name: Create GitHub issue
        uses: actions/github-script@v7
        with:
          script: |
            const message = `${{ steps.extract.outputs.message }}`;
            const userId = `${{ steps.extract.outputs.user_id }}`;
            const username = `${{ steps.extract.outputs.username }}`;
            const firstName = `${{ steps.extract.outputs.first_name }}`;
            const lastName = `${{ steps.extract.outputs.last_name }}`;
            
            const fullName = [firstName, lastName].filter(Boolean).join(' ') || 'Unknown';
            
            const issue = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üí¨ Contact from ${fullName} (@${username})`,
              body: `## Telegram Contact Form Submission
            
            **From:** ${fullName} (@${username})
            **Telegram ID:** ${userId}
            **Telegram Link:** https://t.me/${username}
            
            ### Message
            ${message}
            
            ### Response
            Reply via Telegram: [@${username}](https://t.me/${username})`,
              labels: ['telegram-submission', 'contact-form']
            });
            
            console.log(`‚úÖ Created contact issue #${issue.data.number}`);
  
  # Job 11: Process Telegram PIN publishing submission
  process-telegram-pin:
    name: üîê Process Telegram PIN Publishing
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'repository_dispatch' && github.event.action == 'telegram_pin_submission' ||
      github.event.inputs.task == 'process-telegram-pin'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Extract and validate PIN
        id: validate_pin
        env:
          PIN_HASH_1: ${{ secrets.ORGANIZER_PIN_HASH_1 }}
          PIN_HASH_2: ${{ secrets.ORGANIZER_PIN_HASH_2 }}
          PIN_HASH_3: ${{ secrets.ORGANIZER_PIN_HASH_3 }}
        run: |
          if [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            PIN="${{ github.event.client_payload.pin }}"
            USER_ID="${{ github.event.client_payload.user_id }}"
            USERNAME="${{ github.event.client_payload.username }}"
          else
            PIN="${{ github.event.inputs.telegram_pin }}"
            USER_ID="${{ github.event.inputs.telegram_user_id }}"
            USERNAME="manual"
          fi
          
          # Strip all whitespace from PIN before hashing to match bot & docs behavior
          PIN_STRIPPED="$(echo -n "$PIN" | tr -d '[:space:]')"
          
          # Compute SHA256 hash of stripped PIN
          PIN_HASH=$(echo -n "$PIN_STRIPPED" | sha256sum | awk '{print $1}')
          
          echo "Validating organizer PIN..."
          
          # Check against stored hashes
          VALID=false
          if [ "$PIN_HASH" == "$PIN_HASH_1" ]; then
            VALID=true
            echo "‚úÖ PIN validated (slot 1)"
          elif [ "$PIN_HASH" == "$PIN_HASH_2" ]; then
            VALID=true
            echo "‚úÖ PIN validated (slot 2)"
          elif [ "$PIN_HASH" == "$PIN_HASH_3" ]; then
            VALID=true
            echo "‚úÖ PIN validated (slot 3)"
          else
            echo "‚ùå Invalid PIN"
          fi
          
          echo "valid=$VALID" >> $GITHUB_OUTPUT
          echo "user_id=$USER_ID" >> $GITHUB_OUTPUT
          echo "username=$USERNAME" >> $GITHUB_OUTPUT
      
      - name: Validate and publish event
        if: steps.validate_pin.outputs.valid == 'true'
        env:
          EVENT_JSON: ${{ github.event_name == 'repository_dispatch' && toJson(github.event.client_payload.event_data) || github.event.inputs.telegram_event_json }}
          USER_ID: ${{ steps.validate_pin.outputs.user_id }}
          USERNAME: ${{ steps.validate_pin.outputs.username }}
        run: |
          echo "Validating event JSON..."
          
          # Validate JSON with jq (EVENT_JSON comes from env)
          echo "$EVENT_JSON" | jq empty || {
            echo "‚ùå Invalid JSON"
            exit 1
          }
          
          echo "‚úÖ JSON is valid"
          
          # Add metadata to event using jq (safer than inline Python with triple quotes)
          TIMESTAMP=$(date -u '+%Y-%m-%dT%H:%M:%SZ')
          
          AUGMENTED_JSON=$(echo "$EVENT_JSON" | jq --arg ts "$TIMESTAMP" --arg uid "$USER_ID" --arg uname "$USERNAME" '. + {
            "_comment": "Published by authorized organizer",
            "_published_via": "telegram_pin",
            "_published_at": $ts,
            "_telegram_user_id": $uid,
            "_telegram_username": $uname
          }')
          
          echo "Augmented event JSON:"
          echo "$AUGMENTED_JSON" | jq .
          
          # Write augmented JSON to temp file for safer Python processing
          echo "$AUGMENTED_JSON" > /tmp/augmented_event.json
          
          # Add to events.json using Python with file input (no code injection risk)
          python3 << 'PYCODE'
          import json
          
          # Load existing events
          with open('assets/json/events.json', 'r') as f:
              data = json.load(f)
          
          # Load new event from temp file (safer than inline)
          with open('/tmp/augmented_event.json', 'r') as f:
              new_event = json.load(f)
          
          data['events'].append(new_event)
          
          # Save updated events
          with open('assets/json/events.json', 'w') as f:
              json.dump(data, f, indent=2)
          
          print('‚úÖ Event added to events.json')
          PYCODE
      
      - name: Commit published event
        if: steps.validate_pin.outputs.valid == 'true'
        run: |
          git config user.name "telegram-bot[bot]"
          git config user.email "telegram-bot[bot]@users.noreply.github.com"
          
          git add assets/json/events.json
          git commit -m "feat: publish event via Telegram PIN from @${{ steps.validate_pin.outputs.username }} [automated]"
          git push
          
          echo "‚úÖ Event published to production"
      
      - name: Notify on invalid PIN
        if: steps.validate_pin.outputs.valid == 'false'
        run: |
          echo "‚ö†Ô∏è Invalid PIN submission detected"
          echo "User: ${{ steps.validate_pin.outputs.username }} (ID: ${{ steps.validate_pin.outputs.user_id }})"
          echo "This is logged but no notification is sent to user (security by obscurity)"
