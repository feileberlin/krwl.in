name: ğŸ¤– Event Scraping, Weather Updates & Site Deployment

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# KRWL HOF Community Events - Automated Workflow
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# PURPOSE:
# This is the main automation workflow for the KRWL HOF community events website.
# It handles everything from data collection to deployment in a fully automated way.
#
# WHAT THIS WORKFLOW DOES:
# 1. ğŸ“¥ Collects event data from RSS feeds and HTML sources
# 2. ğŸŒ¤ï¸ Updates weather information and clothing recommendations
# 3. ğŸ”¨ Builds the static website with all latest data
# 4. ğŸš€ Deploys the updated site to GitHub Pages
# 5. âœï¸ Provides editorial tools for event curation
# 6. ğŸ“± Integrates with Telegram bot for community submissions
# 7. ğŸ§ª Runs automated tests and quality checks
#
# WHEN IT RUNS:
# - Automatically twice daily (4 AM and 4 PM Berlin time)
# - On every push to main branch (ensures deployment)
# - On pull requests (for code review and testing)
# - Manually via "Run workflow" button with task selection
# - Via Telegram bot events (flyer submission, contact form, etc.)
#
# WORKFLOW STRUCTURE (7 Phases):
# Phase 1: Configuration Discovery - Read settings and capabilities
# Phase 2: Data Collection - Scrape events and weather
# Phase 3: Build & Generation - Create HTML and update content
# Phase 4: Deployment - Publish to live site
# Phase 5: Editorial & Maintenance - Review events, archive old ones
# Phase 6: Telegram Integration - Process bot submissions
# Phase 7: CI/CD & Quality - Run tests and validation
#
# CONSOLIDATED WORKFLOW - Replaces previous separate workflows:
# - pr-preview.yml - PR preview builds
# - wishlist-ci.yml - Linting and testing
# - config-validation.yml - Configuration validation
# - auto-generate-html.yml - HTML generation (now in full-rebuild job)
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

on:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # TRIGGER 1: Scheduled Runs (Automatic)
  # Runs twice daily to keep the site fresh with latest events
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  schedule:
    # Dynamic scheduling based on config.json scraping.schedule
    # These times are read from scraper capabilities at runtime
    # Default: 04:00 and 16:00 Europe/Berlin (03:00 and 15:00 UTC)
    - cron: '0 3 * * *'   # 4:00 AM Berlin time - Morning update
    - cron: '0 15 * * *'  # 4:00 PM Berlin time - Afternoon update
  
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # TRIGGER 2: Pull Requests (Code Review)
  # Validates changes before merging to main
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      # Only trigger on changes that affect site generation or code quality
      - 'assets/css/**'          # Styles
      - 'assets/js/**'           # JavaScript  
      - 'assets/html/**'         # HTML templates
      - 'assets/json/**'         # JSON data
      - 'config.json'            # Configuration
      - 'src/**'                 # Python source code
      - 'tests/**'               # Test files
      - 'features.json'          # Feature registry
  
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # TRIGGER 3: Push to Main (Deployment)
  # CRITICAL: ALL pushes to main now trigger deployment (no path filters)
  # This ensures every merge results in a deployment - preventing silent failures
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  push:
    branches:
      - main
    # Note: No paths filter here - ALL pushes to main trigger workflow
    # This prevents the "changes merged but not deployed" issue
    # Path-based optimizations are handled within individual jobs
  
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # TRIGGER 4: Telegram Bot Integration
  # Receives events from the Telegram bot for community submissions
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  repository_dispatch:
    types:
      - telegram_flyer_submission    # User uploads event flyer for OCR
      - telegram_contact_submission  # User sends contact form message
      - telegram_pin_submission      # Trusted organizer publishes with PIN
  
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # TRIGGER 5: Manual Execution
  # Run specific tasks on demand via GitHub UI "Run workflow" button
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  workflow_dispatch:
    inputs:
      task:
        description: |
          ğŸ¯ Select the task you want to run:
          
          ğŸ“¥ Data Collection:
          - scrape-only: Get new events without deploying
          - scrape-and-deploy: Get events + deploy immediately
          - scrape-weather: Update weather info only
          
          ğŸ”¨ Build & Deploy:
          - force-deploy: Rebuild everything and deploy
          - update-events: Fast event update (no full rebuild)
          
          âœï¸ Editorial:
          - review-pending: Review and publish awaiting events
          
          ğŸ“± Telegram:
          - process-telegram-flyer: Process flyer submission
          - process-telegram-contact: Process contact message
          - process-telegram-pin: Process PIN publish
          
          ğŸ§ª Diagnostics:
          - info: Show configuration and capabilities
          - run-tests: Run linting and tests
          - validate-config: Check configuration files
        required: true
        type: choice
        options:
          - 'scrape-only'        # Scrape events from RSS/HTML sources without deployment
          - 'scrape-and-deploy'  # Scrape new events and automatically deploy changes to production
          - 'force-deploy'       # Force complete site rebuild and deployment (ignores cache)
          - 'update-events'      # Fast path: Update event data in HTML without full rebuild
          - 'review-pending'     # Editorial workflow: Review and publish pending events awaiting approval
          - 'scrape-weather'     # Fetch current weather and clothing recommendations for map location
          - 'info'               # Display scraper configuration and capabilities (diagnostic tool)
          - 'process-telegram-flyer'    # Process Telegram flyer submission with OCR
          - 'process-telegram-contact'  # Process Telegram contact form submission
          - 'process-telegram-pin'      # Process Telegram PIN publishing submission
          - 'run-tests'          # Run linting and tests (CI job)
          - 'validate-config'    # Validate configuration files
        default: 'scrape-and-deploy'
      
      force_scrape:
        description: |
          ğŸ”„ Force re-scraping even if URLs haven't changed
          (Useful when source sites updated content without changing URLs)
        type: boolean
        default: false
      
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # Editorial Workflow Options (for 'review-pending' task)
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      event_ids:
        description: |
          ğŸ“ Event IDs to publish (comma-separated)
          Examples:
          - "pending_123,pending_456" - Publish specific events
          - "all" - Publish all pending events
        type: string
        required: false
      
      auto_publish_pattern:
        description: |
          ğŸ” Auto-publish pattern (glob syntax)
          Examples:
          - "pending_*" - Publish all pending events
          - "pending_202601*" - Publish January 2026 events
        type: string
        required: false
      
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # Telegram Processing Options (for process-telegram-* tasks)
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      telegram_file_id:
        description: |
          ğŸ“ Telegram file ID (for flyer uploads)
          Format: File ID from Telegram Bot API
        type: string
        required: false
      
      telegram_message:
        description: |
          ğŸ’¬ Contact message text
          The actual message content from user
        type: string
        required: false
      
      telegram_user_id:
        description: |
          ğŸ‘¤ Telegram user ID
          Numeric ID of the user who submitted
        type: string
        required: false
      
      telegram_pin:
        description: |
          ğŸ” 4-digit PIN (for trusted organizers only)
          Used to publish events without review
        type: string
        required: false
      
      telegram_event_json:
        description: |
          ğŸ“‹ Event JSON data (for PIN publishing)
          Complete event object in JSON format
        type: string
        required: false
      
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # Development & Testing Options
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      enable_pr_preview:
        description: |
          ğŸ” Enable PR preview generation
          Creates a preview deployment for pull requests
        type: boolean
        default: true
      
      verbose_tests:
        description: |
          ğŸ› Enable verbose test output
          Shows detailed information from tests and linting
        type: boolean
        default: false

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Permissions Required
# These permissions allow the workflow to interact with GitHub
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
permissions:
  contents: write        # Push commits (weather updates, event data)
  pages: write           # Deploy to GitHub Pages
  id-token: write        # GitHub Pages deployment authentication
  issues: write          # Create issues from Telegram submissions
  pull-requests: write   # Comment on PRs with preview links

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Concurrency Control
# Prevents multiple workflow runs from interfering with each other
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
concurrency:
  group: "website-maintenance"
  cancel-in-progress: false  # Let running workflows finish (don't cancel)

jobs:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # ğŸ“Š PHASE 1: Configuration & Discovery
  # 
  # Purpose: Read configuration and determine scraper capabilities
  # This job runs first to discover what sources are enabled and what
  # capabilities are available, which informs how other jobs will run.
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  discover-capabilities:
    name: ğŸ” Configuration Discovery
    runs-on: ubuntu-latest
    outputs:
      capabilities: ${{ steps.introspect.outputs.capabilities }}
      enabled_sources: ${{ steps.introspect.outputs.enabled_sources }}
      source_count: ${{ steps.introspect.outputs.source_count }}
      scraping_enabled: ${{ steps.introspect.outputs.scraping_enabled }}
      schedule_timezone: ${{ steps.introspect.outputs.schedule_timezone }}
      schedule_times: ${{ steps.introspect.outputs.schedule_times }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Introspect scraper capabilities
        id: introspect
        run: |
          set -e  # Exit on error
          
          echo "ğŸ” Discovering scraper capabilities..."
          
          # Get scraper capabilities via CLI with --json flag for clean output
          # The --json flag suppresses all logging to ensure pure JSON
          if ! CAPABILITIES=$(python3 src/event_manager.py scraper-info --json); then
            echo "âŒ Error: scraper-info command failed"
            echo "Exit code: $?"
            exit 1
          fi
          
          # Validate JSON before proceeding
          if ! echo "$CAPABILITIES" | jq empty 2>/dev/null; then
            echo "âŒ Error: scraper-info did not output valid JSON"
            echo "Raw output:"
            echo "$CAPABILITIES"
            echo ""
            echo "Attempting to extract JSON from output..."
            # Try to extract JSON from mixed output (fallback)
            CAPABILITIES=$(echo "$CAPABILITIES" | sed -n '/^{/,$p')
            if ! echo "$CAPABILITIES" | jq empty 2>/dev/null; then
              echo "âŒ Could not extract valid JSON. Using safe defaults."
              # Use safe fallback values
              echo "enabled_sources=0" >> $GITHUB_OUTPUT
              echo "source_count=0" >> $GITHUB_OUTPUT
              echo "scraping_enabled=false" >> $GITHUB_OUTPUT
              echo "schedule_timezone=Europe/Berlin" >> $GITHUB_OUTPUT
              echo "schedule_times=04:00, 16:00" >> $GITHUB_OUTPUT
              echo "capabilities={}" >> $GITHUB_OUTPUT
              exit 0  # Don't fail the whole workflow
            fi
          fi
          
          # Store capabilities for other jobs
          echo "capabilities<<EOF" >> $GITHUB_OUTPUT
          echo "$CAPABILITIES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          # Extract specific fields for conditional logic with error handling
          ENABLED_SOURCES=$(echo "$CAPABILITIES" | jq -r '.enabled_sources | length' 2>/dev/null || echo "0")
          SCRAPING_ENABLED=$(echo "$CAPABILITIES" | jq -r '.scraping_libraries_installed' 2>/dev/null || echo "false")
          SCHEDULE_TZ=$(echo "$CAPABILITIES" | jq -r '.schedule.timezone // "Europe/Berlin"' 2>/dev/null)
          SCHEDULE_TIMES=$(echo "$CAPABILITIES" | jq -r '.schedule.times | join(", ")' 2>/dev/null || echo "04:00, 16:00")
          
          echo "enabled_sources=$ENABLED_SOURCES" >> $GITHUB_OUTPUT
          echo "source_count=$ENABLED_SOURCES" >> $GITHUB_OUTPUT
          echo "scraping_enabled=$SCRAPING_ENABLED" >> $GITHUB_OUTPUT
          echo "schedule_timezone=$SCHEDULE_TZ" >> $GITHUB_OUTPUT
          echo "schedule_times=$SCHEDULE_TIMES" >> $GITHUB_OUTPUT
          
          echo "âœ“ Scraper capabilities discovered"
          echo "  - Enabled sources: $ENABLED_SOURCES"
          echo "  - Scraping enabled: $SCRAPING_ENABLED"
          echo "  - Schedule: $SCHEDULE_TIMES ($SCHEDULE_TZ)"
      
      - name: Display capabilities
        run: |
          echo "## ğŸ” Scraper Capabilities" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          echo '${{ steps.introspect.outputs.capabilities }}' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

  scrape-events:
    name: ğŸ“… Scrape Events
    runs-on: ubuntu-latest
    needs: discover-capabilities
    if: |
      (github.event_name == 'schedule' || 
       github.event.inputs.task == 'scrape-only' || 
       github.event.inputs.task == 'scrape-and-deploy' ||
       github.event.inputs.force_scrape == 'true') &&
      needs.discover-capabilities.outputs.scraping_enabled == 'true' &&
      needs.discover-capabilities.outputs.source_count != '0'
    
    outputs:
      changes_detected: ${{ steps.check_changes.outputs.changes_detected }}
      pending_count: ${{ steps.count_pending.outputs.pending_count }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Configure Git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
      
      - name: Run scraper (adaptive)
        id: scrape
        run: |
          echo "ğŸ” Starting event scraping..."
          echo "Scraping from ${{ needs.discover-capabilities.outputs.source_count }} enabled sources"
          
          # Run scraper using event_manager CLI
          python3 src/event_manager.py scrape
          
          echo "âœ“ Scraping completed"
      
      - name: Check for changes
        id: check_changes
        run: |
          if [[ -n $(git status --porcelain assets/json/) ]]; then
            echo "changes_detected=true" >> $GITHUB_OUTPUT
            echo "âœ“ New events detected"
          else
            echo "changes_detected=false" >> $GITHUB_OUTPUT
            echo "â„¹ No new events found"
          fi
      
      - name: Count pending events
        id: count_pending
        run: |
          if [ -f assets/json/pending_events.json ]; then
            COUNT=$(python3 -c "import json; data = json.load(open('assets/json/pending_events.json')); print(len(data.get('pending_events', [])))")
            echo "pending_count=$COUNT" >> $GITHUB_OUTPUT
            echo "â„¹ Pending events: $COUNT"
          else
            echo "pending_count=0" >> $GITHUB_OUTPUT
            echo "â„¹ Pending events: 0"
          fi
      
      - name: Commit and push changes
        if: steps.check_changes.outputs.changes_detected == 'true'
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M UTC')
          git add assets/json/
          git commit -m "chore: automated event scraping - $TIMESTAMP"
          
          # Pull with rebase to handle concurrent changes
          if ! git pull --rebase origin main; then
            echo "âŒ Rebase failed - manual intervention required"
            git rebase --abort || true
            exit 1
          fi
          
          git push
          echo "âœ“ Changes committed and pushed"
      
      - name: Generate scraping summary
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
          PENDING_COUNT="${{ steps.count_pending.outputs.pending_count }}"
          CHANGES="${{ steps.check_changes.outputs.changes_detected }}"
          
          echo "## ğŸ” Event Scraping Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Date/Time:** $TIMESTAMP" >> $GITHUB_STEP_SUMMARY
          echo "**Sources:** ${{ needs.discover-capabilities.outputs.source_count }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$CHANGES" == "true" ]; then
            echo "**Status:** âœ… New events found" >> $GITHUB_STEP_SUMMARY
          else
            echo "**Status:** â„¹ï¸ No new events" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "**Pending Events:** $PENDING_COUNT" >> $GITHUB_STEP_SUMMARY
          
          if [ "$PENDING_COUNT" -gt "0" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "âš ï¸ **Action Required:** $PENDING_COUNT events awaiting review" >> $GITHUB_STEP_SUMMARY
          fi

  scrape-weather:
    name: ğŸŒ¤ï¸ Scrape Weather
    runs-on: ubuntu-latest
    needs: discover-capabilities
    if: |
      github.event_name == 'schedule' ||
      github.event.inputs.task == 'scrape-weather' ||
      github.event.inputs.task == 'scrape-and-deploy'
    
    outputs:
      weather_scraped: ${{ steps.scrape_weather.outputs.weather_scraped }}
      artifact_uploaded: ${{ steps.set_artifact_uploaded_output.outputs.artifact_uploaded }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Configure Git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
      
      - name: Run weather scraper
        id: scrape_weather
        run: |
          echo "ğŸŒ¤ï¸ Scraping weather and dresscode..."
          
          # Run weather scraper using event_manager CLI
          if python3 src/event_manager.py scrape-weather; then
            echo "weather_scraped=true" >> $GITHUB_OUTPUT
            echo "âœ“ Weather scraping completed"
          else
            echo "weather_scraped=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ Weather scraping failed (non-critical)"
          fi
      
      - name: Check for changes
        id: check_changes
        run: |
          if [[ -n $(git status --porcelain assets/json/weather_cache.json) ]]; then
            echo "changes_detected=true" >> $GITHUB_OUTPUT
            echo "âœ“ Weather cache updated"
          else
            echo "changes_detected=false" >> $GITHUB_OUTPUT
            echo "â„¹ No weather changes"
          fi
      
      - name: Update weather in HTML (fast update, no rebuild)
        if: steps.check_changes.outputs.changes_detected == 'true'
        run: |
          echo "âš¡ Updating weather data in HTML without full rebuild..."
          
          # Fast update: inject weather data into existing HTML
          if python3 src/event_manager.py update-weather; then
            echo "âœ“ Weather data updated in HTML"
          else
            echo "âš ï¸ Weather update in HTML failed (will need full rebuild)"
          fi
      
      - name: Commit and push weather cache
        if: steps.check_changes.outputs.changes_detected == 'true'
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M UTC')
          # Only commit weather cache (public/index.html is gitignored and regenerated on CI runs)
          git add assets/json/weather_cache.json
          git commit -m "chore: update weather data - $TIMESTAMP [skip ci]"
          
          # Pull with rebase to handle concurrent changes
          if ! git pull --rebase origin main; then
            echo "âŒ Rebase failed - manual intervention required"
            git rebase --abort || true
            exit 1
          fi
          
          git push
          echo "âœ“ Weather cache committed and pushed (HTML will be regenerated on next CI run)"
      
      - name: Generate weather summary
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
          WEATHER_SCRAPED="${{ steps.scrape_weather.outputs.weather_scraped }}"
          
          echo "## ğŸŒ¤ï¸ Weather Scraping Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Date/Time:** $TIMESTAMP" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$WEATHER_SCRAPED" == "true" ]; then
            echo "**Status:** âœ… Weather scraped successfully" >> $GITHUB_STEP_SUMMARY
            
            # Display weather data if available
            if [ -f assets/json/weather_cache.json ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "**Weather Data:**" >> $GITHUB_STEP_SUMMARY
              echo '```json' >> $GITHUB_STEP_SUMMARY
              cat assets/json/weather_cache.json >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "**Status:** âš ï¸ Weather scraping failed" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Upload artifact (fast weather update)
        id: upload_artifact
        if: steps.check_changes.outputs.changes_detected == 'true'
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./public
      
      - name: Set artifact uploaded output
        if: steps.check_changes.outputs.changes_detected == 'true'
        run: |
          echo "artifact_uploaded=true" >> $GITHUB_OUTPUT

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # ğŸ”¨ PHASE 3: Build & Generation
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  update-events:
    name: âš¡ Fast Event Update
    runs-on: ubuntu-latest
    needs: [discover-capabilities, scrape-events, scrape-weather]
    if: |
      always() &&
      (github.event.inputs.task == 'update-events' ||
       (github.event_name == 'push' && 
        contains(github.event.head_commit.modified, 'assets/json/events.json')))
    
    outputs:
      artifact_uploaded: ${{ steps.upload_artifact.outputs.artifact_uploaded }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Fast update events data
        run: |
          echo "âš¡ Fast updating events data..."
          python3 src/event_manager.py update
          echo "âœ“ Events data updated"
      
      - name: Upload artifact
        id: upload_artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./public
      
      - name: Set artifact uploaded output
        run: |
          echo "artifact_uploaded=true" >> $GITHUB_OUTPUT

  full-rebuild:
    name: ğŸ”¨ Full Site Rebuild
    runs-on: ubuntu-latest
    needs: [discover-capabilities, scrape-events, scrape-weather]
    if: |
      always() &&
      (github.event.inputs.task == 'force-deploy' ||
       github.event.inputs.task == 'scrape-and-deploy' ||
       github.event_name == 'push')
    
    outputs:
      artifact_uploaded: ${{ steps.upload_artifact.outputs.artifact_uploaded }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Fetch third-party dependencies
        run: |
          echo "ğŸ“¦ Fetching dependencies..."
          python3 src/event_manager.py dependencies fetch
      
      - name: Verify dependencies
        run: |
          python3 src/event_manager.py dependencies check
      
      - name: Generate Lucide icon map
        run: |
          echo "ğŸ¨ Generating Lucide icons map..."
          python3 src/event_manager.py generate-icons
          echo "âœ“ Icon map generated"
      
      - name: Full site generation
        run: |
          echo "ğŸ”¨ Building site..."
          python3 src/event_manager.py generate
          echo "âœ“ Site built successfully"
      
      - name: Add deployment timestamp
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
          if [ -f public/index.html ]; then
            sed -i "s/BUILD_TIMESTAMP_PLACEHOLDER/$TIMESTAMP/g" public/index.html
          fi
      
      - name: Upload artifact
        id: upload_artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./public
      
      - name: Set artifact uploaded output
        run: |
          echo "artifact_uploaded=true" >> $GITHUB_OUTPUT

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # ğŸš€ PHASE 4: Deployment
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  deploy:
    name: ğŸš€ Deploy to Production
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: [update-events, full-rebuild, scrape-weather]
    if: |
      always() &&
      (needs.update-events.outputs.artifact_uploaded == 'true' || 
       needs.full-rebuild.outputs.artifact_uploaded == 'true' ||
       needs.scrape-weather.outputs.artifact_uploaded == 'true')
    
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
      
      - name: Deployment summary
        run: |
          echo "## ğŸš€ Deployment Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**URL:** ${{ steps.deployment.outputs.page_url }}" >> $GITHUB_STEP_SUMMARY
          echo "**Time:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # âœï¸ PHASE 5: Editorial & Maintenance (Conditional)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  show-info:
    name: ğŸ“Š Show Configuration
    runs-on: ubuntu-latest
    needs: discover-capabilities
    if: github.event.inputs.task == 'info'
    
    steps:
      - name: Display full capabilities
        run: |
          echo "## ğŸ” Complete Scraper Capabilities" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          echo '${{ needs.discover-capabilities.outputs.capabilities }}' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Key Information" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Enabled Sources:** ${{ needs.discover-capabilities.outputs.source_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Scraping Libraries:** ${{ needs.discover-capabilities.outputs.scraping_enabled }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Schedule:** ${{ needs.discover-capabilities.outputs.schedule_times }} (${{ needs.discover-capabilities.outputs.schedule_timezone }})" >> $GITHUB_STEP_SUMMARY

  review-pending:
    name: âœï¸ Review & Publish Events
    runs-on: ubuntu-latest
    needs: discover-capabilities
    if: |
      github.event.inputs.task == 'review-pending' ||
      (github.event.inputs.auto_publish_pattern != '' && github.event.inputs.auto_publish_pattern != null)
    
    outputs:
      published_count: ${{ steps.publish.outputs.published_count }}
      events_published: ${{ steps.publish.outputs.events_published }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # Ensure we have latest changes
          ref: main
      
      - name: Pull latest changes
        run: |
          git pull origin main
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Configure Git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
      
      - name: List pending events
        id: list_pending
        run: |
          echo "ğŸ“‹ Listing pending events..."
          
          # List pending events (if list-pending command exists)
          if python3 src/event_manager.py list-pending > pending_list.txt 2>&1; then
            cat pending_list.txt
          else
            echo "âš ï¸  Could not run list-pending command"
          fi
          
          # Count pending events with error handling
          PENDING_COUNT=$(python3 -c "
          import json
          try:
              with open('assets/json/pending_events.json', 'r') as f:
                  data = json.load(f)
              print(len(data.get('pending_events', [])))
          except (FileNotFoundError, json.JSONDecodeError, KeyError) as e:
              print('0')
          " 2>/dev/null)
          
          # Validate the count is a valid number, default to 0 if not
          if [[ -z "$PENDING_COUNT" || ! "$PENDING_COUNT" =~ ^[0-9]+$ ]]; then
            PENDING_COUNT=0
          fi
          
          echo "pending_count=${PENDING_COUNT}" >> "$GITHUB_OUTPUT"
          echo "â„¹ Found $PENDING_COUNT pending events"
          
          # Add to summary
          echo "## ğŸ“‹ Pending Events Review" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Pending Events:** $PENDING_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$PENDING_COUNT" -gt 0 ]; then
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat pending_list.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "â„¹ï¸ No pending events to review." >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Publish events (auto or manual)
        id: publish
        run: |
          echo "ğŸ”„ Publishing events..."
          PUBLISHED_COUNT=0
          PUBLISHED_IDS=""
          
          # Check for auto-publish pattern
          AUTO_PATTERN="${{ github.event.inputs.auto_publish_pattern }}"
          MANUAL_IDS="${{ github.event.inputs.event_ids }}"
          
          if [ -n "$AUTO_PATTERN" ]; then
            echo "ğŸ“¦ Auto-publishing events matching: $AUTO_PATTERN"
            
            # Use bulk-publish with pattern
            if python3 src/event_manager.py bulk-publish "$AUTO_PATTERN"; then
              # Count how many were published
              PUBLISHED_COUNT=$(git diff --cached --name-only | grep -c "events.json" || echo "0")
              PUBLISHED_IDS="Pattern: $AUTO_PATTERN"
              echo "âœ“ Auto-published events matching pattern"
            else
              echo "âš ï¸ Auto-publish failed or no events matched pattern"
            fi
            
          elif [ -n "$MANUAL_IDS" ]; then
            echo "ğŸ“ Publishing specific events: $MANUAL_IDS"
            
            if [ "$MANUAL_IDS" = "all" ]; then
              # Publish all pending events
              echo "Publishing ALL pending events..."
              python3 src/event_manager.py bulk-publish "pending_*"
              PUBLISHED_COUNT=$(git diff --cached --name-only | grep -c "events.json" || echo "0")
              PUBLISHED_IDS="all"
            else
              # Publish specific IDs (comma-separated)
              IFS=',' read -ra IDS_ARRAY <<< "$MANUAL_IDS"
              for EVENT_ID in "${IDS_ARRAY[@]}"; do
                EVENT_ID=$(echo "$EVENT_ID" | xargs)  # Trim whitespace
                echo "Publishing: $EVENT_ID"
                if python3 src/event_manager.py publish "$EVENT_ID"; then
                  PUBLISHED_COUNT=$((PUBLISHED_COUNT + 1))
                  PUBLISHED_IDS="$PUBLISHED_IDS $EVENT_ID"
                else
                  echo "âš ï¸ Failed to publish: $EVENT_ID"
                fi
              done
            fi
            
          else
            echo "âš ï¸ No events specified for publishing"
            echo "Provide either 'event_ids' or 'auto_publish_pattern'"
          fi
          
          echo "published_count=$PUBLISHED_COUNT" >> $GITHUB_OUTPUT
          echo "events_published=$PUBLISHED_IDS" >> $GITHUB_OUTPUT
          
          echo "âœ“ Published $PUBLISHED_COUNT event(s)"
          
          # Add to summary
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Publishing Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Published:** $PUBLISHED_COUNT event(s)" >> $GITHUB_STEP_SUMMARY
          if [ -n "$PUBLISHED_IDS" ]; then
            echo "- **IDs:** $PUBLISHED_IDS" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Commit and push changes
        if: steps.publish.outputs.published_count != '0'
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M UTC')
          PUBLISHED_COUNT="${{ steps.publish.outputs.published_count }}"
          
          git add assets/json/
          git commit -m "chore: publish $PUBLISHED_COUNT event(s) - $TIMESTAMP"
          
          # Pull with rebase to handle concurrent changes
          if ! git pull --rebase origin main; then
            echo "âŒ Rebase failed - manual intervention required"
            git rebase --abort || true
            exit 1
          fi
          
          git push
          echo "âœ“ Changes committed and pushed"
      
      - name: Trigger deployment
        if: steps.publish.outputs.published_count != '0'
        run: |
          echo "ğŸš€ Events published, deployment will be triggered automatically"
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… **Deployment triggered automatically** (push to events.json)" >> $GITHUB_STEP_SUMMARY
  
  archive-monthly:
    name: ğŸ—„ï¸ Monthly Event Archive
    runs-on: ubuntu-latest
    # Run only on schedule (first day of month) or manual trigger
    if: |
      github.event_name == 'schedule' ||
      github.event.inputs.task == 'archive-monthly'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Read archiving configuration
        id: config
        run: |
          echo "ğŸ“‹ Reading archiving configuration from config.json..."
          
          # Extract archiving config
          ENABLED=$(jq -r '.archiving.enabled // true' config.json)
          RETENTION_DAYS=$(jq -r '.archiving.retention.active_window_days // 60' config.json)
          SCHEDULE_DAY=$(jq -r '.archiving.schedule.day_of_month // 1' config.json)
          SCHEDULE_TIME=$(jq -r '.archiving.schedule.time // "02:00"' config.json)
          
          echo "enabled=$ENABLED" >> $GITHUB_OUTPUT
          echo "retention_days=$RETENTION_DAYS" >> $GITHUB_OUTPUT
          echo "schedule_day=$SCHEDULE_DAY" >> $GITHUB_OUTPUT
          echo "schedule_time=$SCHEDULE_TIME" >> $GITHUB_OUTPUT
          
          echo "âœ“ Archiving config:"
          echo "  - Enabled: $ENABLED"
          echo "  - Retention: $RETENTION_DAYS days"
          echo "  - Schedule: Day $SCHEDULE_DAY at $SCHEDULE_TIME UTC"
      
      - name: Display configuration
        run: |
          echo "## ğŸ—„ï¸ Archiving Configuration" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Enabled:** ${{ steps.config.outputs.enabled }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Retention:** ${{ steps.config.outputs.retention_days }} days" >> $GITHUB_STEP_SUMMARY
          echo "- **Schedule:** Day ${{ steps.config.outputs.schedule_day }} at ${{ steps.config.outputs.schedule_time }} UTC" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
      
      - name: Run archiving (dry-run first)
        id: dry_run
        run: |
          echo "ğŸ” Running dry-run to preview archiving..."
          python3 src/event_manager.py archive-monthly --dry-run | tee dry_run_output.txt
          
          # Extract results
          ARCHIVED_COUNT=$(grep "Would archive:" dry_run_output.txt | awk '{print $3}' || echo "0")
          ACTIVE_COUNT=$(grep "Remaining active:" dry_run_output.txt | awk '{print $3}' || echo "0")
          
          echo "archived_count=$ARCHIVED_COUNT" >> $GITHUB_OUTPUT
          echo "active_count=$ACTIVE_COUNT" >> $GITHUB_OUTPUT
          
          echo "âœ“ Dry-run complete:"
          echo "  - Would archive: $ARCHIVED_COUNT events"
          echo "  - Would remain active: $ACTIVE_COUNT events"
      
      - name: Display dry-run results
        run: |
          echo "### ğŸ” Dry-Run Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Would archive:** ${{ steps.dry_run.outputs.archived_count }} events" >> $GITHUB_STEP_SUMMARY
          echo "- **Would remain active:** ${{ steps.dry_run.outputs.active_count }} events" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
      
      - name: Run actual archiving
        id: archive
        if: |
          steps.config.outputs.enabled == 'true' &&
          steps.dry_run.outputs.archived_count != '0'
        run: |
          echo "ğŸ—„ï¸ Running actual archiving..."
          python3 src/event_manager.py archive-monthly | tee archive_output.txt
          
          # Extract results
          ARCHIVED_COUNT=$(grep "Archived:" archive_output.txt | awk '{print $2}' || echo "0")
          
          echo "archived_count=$ARCHIVED_COUNT" >> $GITHUB_OUTPUT
          echo "archiving_done=true" >> $GITHUB_OUTPUT
          
          echo "âœ“ Archiving complete: $ARCHIVED_COUNT events archived"
      
      - name: Display archiving results
        if: steps.archive.outputs.archiving_done == 'true'
        run: |
          echo "### âœ… Archiving Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Archived:** ${{ steps.archive.outputs.archived_count }} events" >> $GITHUB_STEP_SUMMARY
          echo "- **Archive location:** \`assets/json/events/archived/\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
      
      - name: Commit archived events
        if: steps.archive.outputs.archiving_done == 'true'
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M UTC')
          ARCHIVED_COUNT="${{ steps.archive.outputs.archived_count }}"
          
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          git add assets/json/events/
          git add assets/json/events.json
          git commit -m "chore: archive $ARCHIVED_COUNT old event(s) - $TIMESTAMP [automated]"
          
          # Pull with rebase to handle concurrent changes
          if ! git pull --rebase origin main; then
            echo "âŒ Rebase failed - manual intervention required"
            git rebase --abort || true
            exit 1
          fi
          
          git push
          echo "âœ“ Archived events committed and pushed"
      
      - name: No archiving needed
        if: |
          steps.config.outputs.enabled == 'false' ||
          steps.dry_run.outputs.archived_count == '0'
        run: |
          if [ "${{ steps.config.outputs.enabled }}" == "false" ]; then
            echo "â„¹ï¸ Archiving is disabled in config.json"
            echo "---" >> $GITHUB_STEP_SUMMARY
            echo "â„¹ï¸ **Archiving disabled** in config.json" >> $GITHUB_STEP_SUMMARY
          else
            echo "âœ“ No events to archive (all within retention window)"
            echo "---" >> $GITHUB_STEP_SUMMARY
            echo "âœ… **No archiving needed** - All events within retention window" >> $GITHUB_STEP_SUMMARY
          fi
  
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # ğŸ“± PHASE 6: Telegram Integration (Conditional)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  process-telegram-flyer:
    name: "ğŸ“¸ Telegram: Flyer OCR"
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'repository_dispatch' && github.event.action == 'telegram_flyer_submission' ||
      github.event.inputs.task == 'process-telegram-flyer'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          
          # Install Tesseract OCR
          sudo apt-get update
          sudo apt-get install -y tesseract-ocr tesseract-ocr-deu tesseract-ocr-eng
          
          echo "âœ… Dependencies installed"
      
      - name: Download Telegram file
        env:
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
        run: |
          # Get file info from payload or inputs
          if [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            FILE_ID="${{ github.event.client_payload.file_id }}"
            FILE_NAME="${{ github.event.client_payload.file_name }}"
            USER_ID="${{ github.event.client_payload.user_id }}"
            USERNAME="${{ github.event.client_payload.username }}"
            CAPTION="${{ github.event.client_payload.caption }}"
          else
            FILE_ID="${{ github.event.inputs.telegram_file_id }}"
            FILE_NAME=""
            USER_ID="${{ github.event.inputs.telegram_user_id }}"
            USERNAME="manual"
            CAPTION=""
          fi
          
          if [ -z "$FILE_ID" ]; then
            echo "âŒ No Telegram file_id provided in event payload or inputs."
            exit 1
          fi
          
          echo "USER_ID=$USER_ID" >> $GITHUB_ENV
          echo "USERNAME=$USERNAME" >> $GITHUB_ENV
          echo "CAPTION=$CAPTION" >> $GITHUB_ENV
          
          echo "Fetching flyer for file_id: $FILE_ID from user $USER_ID"
          
          # Ensure cache directory exists
          mkdir -p .cache/telegram
          
          # Use Telegram Bot API to resolve file_path from file_id
          API_URL="https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/getFile?file_id=$FILE_ID"
          FILE_PATH=$(curl -s "$API_URL" | python3 -c 'import sys, json; data = json.load(sys.stdin); print(data.get("result", {}).get("file_path", ""))' 2>/dev/null || echo "")
          
          if [ -z "$FILE_PATH" ]; then
            echo "âŒ Failed to resolve Telegram file_path for file_id: $FILE_ID"
            exit 1
          fi
          
          # Derive FILE_NAME from Telegram file_path if not explicitly provided
          if [ -z "$FILE_NAME" ]; then
            FILE_NAME="$(basename "$FILE_PATH")"
            echo "Derived FILE_NAME from Telegram file_path: $FILE_NAME"
          fi
          
          # Persist final FILE_NAME for downstream steps
          echo "FILE_NAME=$FILE_NAME" >> $GITHUB_ENV
          
          DOWNLOAD_URL="https://api.telegram.org/file/bot${TELEGRAM_BOT_TOKEN}/$FILE_PATH"
          echo "Downloading Telegram file from: $DOWNLOAD_URL"
          if ! curl -s -L "$DOWNLOAD_URL" -o ".cache/telegram/$FILE_NAME"; then
            echo "âŒ Failed to download Telegram file to .cache/telegram/$FILE_NAME"
            exit 1
          fi
          
          echo "âœ… Telegram file downloaded to .cache/telegram/$FILE_NAME"
      
      - name: Run Tesseract OCR
        id: ocr
        run: |
          # Create cache directory (should already exist from previous step, but ensure it)
          mkdir -p .cache/telegram
          
          # Check if file exists in cache (downloaded from Telegram in previous step)
          if [ ! -f ".cache/telegram/$FILE_NAME" ]; then
            echo "âŒ File not found at expected location: .cache/telegram/$FILE_NAME"
            echo "This usually indicates a problem resolving or downloading the Telegram file."
            exit 1
          fi
          
          # Run OCR (German + English)
          echo "ğŸ” Running OCR on $FILE_NAME..."
          tesseract ".cache/telegram/$FILE_NAME" ".cache/telegram/ocr_output" -l deu+eng --psm 6
          
          # Read OCR output
          OCR_TEXT=$(cat .cache/telegram/ocr_output.txt 2>/dev/null || echo "")
          
          if [ -z "$OCR_TEXT" ]; then
            echo "âš ï¸ No text extracted from flyer"
            OCR_TEXT="No text could be extracted"
          fi
          
          echo "âœ… OCR completed"
          echo "OCR output preview:"
          echo "$OCR_TEXT" | head -10
          
          # Save OCR text to environment (truncate for GitHub limits)
          echo "OCR_TEXT<<EOF" >> $GITHUB_ENV
          echo "$OCR_TEXT" | head -50 >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV
      
      - name: Create draft event JSON
        id: create_draft
        env:
          USER_ID: ${{ env.USER_ID }}
          USERNAME: ${{ env.USERNAME }}
          FILE_NAME: ${{ env.FILE_NAME }}
          CAPTION: ${{ env.CAPTION }}
          OCR_TEXT: ${{ env.OCR_TEXT }}
        run: |
          TIMESTAMP=$(date -u '+%Y-%m-%d_%H-%M-%S')
          DRAFT_FILE="assets/json/pending_events_telegram_${USER_ID}_${TIMESTAMP}.json"
          
          # Create draft event with OCR text using environment variables (safer than inline)
          python3 << 'PYCODE'
          import json
          import os
          import sys
          from datetime import datetime
          
          user_id = os.environ.get("USER_ID", "")
          ocr_text = os.environ.get("OCR_TEXT", "")
          username = os.environ.get("USERNAME", "")
          file_name = os.environ.get("FILE_NAME", "")
          caption = os.environ.get("CAPTION", "")
          timestamp = os.environ.get("TIMESTAMP", "")
          
          draft_file = os.environ.get("DRAFT_FILE", "")
          
          draft = {
              'id': f'telegram_flyer_{user_id}_{timestamp}',
              'title': 'Telegram Flyer Submission',
              'description': ocr_text,
              'teaser': 'Event submitted via Telegram flyer upload',
              'location': {
                  'name': 'Hof',
                  'lat': 50.3167,
                  'lon': 11.9167,
                  'address_hidden': True
              },
              'start_time': datetime.now().isoformat(),
              'end_time': None,
              'url': None,
              'source': 'telegram',
              'scraped_at': datetime.now().isoformat(),
              'status': 'pending',
              'category': 'community',
              'metadata': {
                  'telegram_user_id': user_id,
                  'telegram_username': username,
                  'telegram_file_name': file_name,
                  'telegram_caption': caption,
                  'submitted_via': 'telegram_flyer_ocr',
                  'needs_review': True
              }
          }
          
          with open(draft_file, 'w') as f:
              json.dump(draft, f, indent=2)
          
          print(f'Created draft: {draft_file}')
          PYCODE
          
          echo "TIMESTAMP=$TIMESTAMP" >> $GITHUB_ENV
          echo "DRAFT_FILE=$DRAFT_FILE" >> $GITHUB_ENV
          echo "draft_file=$DRAFT_FILE" >> $GITHUB_OUTPUT
          echo "âœ… Draft event created: $DRAFT_FILE"
      
      - name: Commit draft event
        run: |
          git config user.name "telegram-bot[bot]"
          git config user.email "telegram-bot[bot]@users.noreply.github.com"
          
          git add "${{ steps.create_draft.outputs.draft_file }}"
          git commit -m "feat: telegram flyer submission from user $USER_ID [needs-review]"
          git push
          
          echo "âœ… Draft event committed"
      
      - name: Create GitHub issue
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const draftFile = '${{ steps.create_draft.outputs.draft_file }}';
            const draftData = JSON.parse(fs.readFileSync(draftFile, 'utf8'));
            
            const issue = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ğŸ“¸ Telegram Flyer Submission from @${draftData.metadata.telegram_username}`,
              body: `## Telegram Flyer Submission
            
            **User:** @${draftData.metadata.telegram_username} (ID: ${draftData.metadata.telegram_user_id})
            **File:** ${draftData.metadata.telegram_file_name}
            **Caption:** ${draftData.metadata.telegram_caption || 'None'}
            
            ### OCR Extracted Text
            \`\`\`
            ${draftData.description}
            \`\`\`
            
            ### Draft Event File
            - File: \`${draftFile}\`
            - Status: Needs editorial review
            
            ### Next Steps
            1. Review the OCR-extracted text above
            2. Edit the draft JSON file to correct any OCR errors
            3. Add proper event details (title, date, location, etc.)
            4. Publish the event using the editorial workflow
            
            ### Actions
            - To publish: Run workflow with task \`review-pending\`
            - To edit: Modify \`${draftFile}\` directly in repository`,
              labels: ['telegram-submission', 'needs-review', 'flyer']
            });
            
            console.log(`âœ… Created issue #${issue.data.number}`);
  
  process-telegram-contact:
    name: "ğŸ’¬ Telegram: Contact Form"
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'repository_dispatch' && github.event.action == 'telegram_contact_submission' ||
      github.event.inputs.task == 'process-telegram-contact'
    
    steps:
      - name: Extract message data
        id: extract
        run: |
          if [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            MESSAGE="${{ github.event.client_payload.message }}"
            USER_ID="${{ github.event.client_payload.user_id }}"
            USERNAME="${{ github.event.client_payload.username }}"
            FIRST_NAME="${{ github.event.client_payload.first_name }}"
            LAST_NAME="${{ github.event.client_payload.last_name }}"
          else
            MESSAGE="${{ github.event.inputs.telegram_message }}"
            USER_ID="${{ github.event.inputs.telegram_user_id }}"
            USERNAME="manual"
            FIRST_NAME=""
            LAST_NAME=""
          fi
          
          echo "message=$MESSAGE" >> $GITHUB_OUTPUT
          echo "user_id=$USER_ID" >> $GITHUB_OUTPUT
          echo "username=$USERNAME" >> $GITHUB_OUTPUT
          echo "first_name=$FIRST_NAME" >> $GITHUB_OUTPUT
          echo "last_name=$LAST_NAME" >> $GITHUB_OUTPUT
      
      - name: Create GitHub issue
        uses: actions/github-script@v7
        with:
          script: |
            const message = `${{ steps.extract.outputs.message }}`;
            const userId = `${{ steps.extract.outputs.user_id }}`;
            const username = `${{ steps.extract.outputs.username }}`;
            const firstName = `${{ steps.extract.outputs.first_name }}`;
            const lastName = `${{ steps.extract.outputs.last_name }}`;
            
            const fullName = [firstName, lastName].filter(Boolean).join(' ') || 'Unknown';
            
            const issue = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ğŸ’¬ Contact from ${fullName} (@${username})`,
              body: `## Telegram Contact Form Submission
            
            **From:** ${fullName} (@${username})
            **Telegram ID:** ${userId}
            **Telegram Link:** https://t.me/${username}
            
            ### Message
            ${message}
            
            ### Response
            Reply via Telegram: [@${username}](https://t.me/${username})`,
              labels: ['telegram-submission', 'contact-form']
            });
            
            console.log(`âœ… Created contact issue #${issue.data.number}`);
  
  process-telegram-pin:
    name: "ğŸ” Telegram: PIN Publish"
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'repository_dispatch' && github.event.action == 'telegram_pin_submission' ||
      github.event.inputs.task == 'process-telegram-pin'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Extract and validate PIN
        id: validate_pin
        env:
          PIN_HASH_1: ${{ secrets.ORGANIZER_PIN_HASH_1 }}
          PIN_HASH_2: ${{ secrets.ORGANIZER_PIN_HASH_2 }}
          PIN_HASH_3: ${{ secrets.ORGANIZER_PIN_HASH_3 }}
        run: |
          if [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            PIN="${{ github.event.client_payload.pin }}"
            USER_ID="${{ github.event.client_payload.user_id }}"
            USERNAME="${{ github.event.client_payload.username }}"
          else
            PIN="${{ github.event.inputs.telegram_pin }}"
            USER_ID="${{ github.event.inputs.telegram_user_id }}"
            USERNAME="manual"
          fi
          
          # Strip all whitespace from PIN before hashing to match bot & docs behavior
          PIN_STRIPPED="$(echo -n "$PIN" | tr -d '[:space:]')"
          
          # Compute SHA256 hash of stripped PIN
          PIN_HASH=$(echo -n "$PIN_STRIPPED" | sha256sum | awk '{print $1}')
          
          echo "Validating organizer PIN..."
          
          # Check against stored hashes
          VALID=false
          if [ "$PIN_HASH" == "$PIN_HASH_1" ]; then
            VALID=true
            echo "âœ… PIN validated (slot 1)"
          elif [ "$PIN_HASH" == "$PIN_HASH_2" ]; then
            VALID=true
            echo "âœ… PIN validated (slot 2)"
          elif [ "$PIN_HASH" == "$PIN_HASH_3" ]; then
            VALID=true
            echo "âœ… PIN validated (slot 3)"
          else
            echo "âŒ Invalid PIN"
          fi
          
          echo "valid=$VALID" >> $GITHUB_OUTPUT
          echo "user_id=$USER_ID" >> $GITHUB_OUTPUT
          echo "username=$USERNAME" >> $GITHUB_OUTPUT
      
      - name: Validate and publish event
        if: steps.validate_pin.outputs.valid == 'true'
        env:
          EVENT_JSON: ${{ github.event_name == 'repository_dispatch' && toJson(github.event.client_payload.event_data) || github.event.inputs.telegram_event_json }}
          USER_ID: ${{ steps.validate_pin.outputs.user_id }}
          USERNAME: ${{ steps.validate_pin.outputs.username }}
        run: |
          echo "Validating event JSON..."
          
          # Validate JSON with jq (EVENT_JSON comes from env)
          echo "$EVENT_JSON" | jq empty || {
            echo "âŒ Invalid JSON"
            exit 1
          }
          
          echo "âœ… JSON is valid"
          
          # Add metadata to event using jq (safer than inline Python with triple quotes)
          TIMESTAMP=$(date -u '+%Y-%m-%dT%H:%M:%SZ')
          
          AUGMENTED_JSON=$(echo "$EVENT_JSON" | jq --arg ts "$TIMESTAMP" --arg uid "$USER_ID" --arg uname "$USERNAME" '. + {
            "_comment": "Published by authorized organizer",
            "_published_via": "telegram_pin",
            "_published_at": $ts,
            "_telegram_user_id": $uid,
            "_telegram_username": $uname
          }')
          
          echo "Augmented event JSON:"
          echo "$AUGMENTED_JSON" | jq .
          
          # Write augmented JSON to temp file for safer Python processing
          echo "$AUGMENTED_JSON" > /tmp/augmented_event.json
          
          # Add to events.json using Python with file input (no code injection risk)
          python3 << 'PYCODE'
          import json
          
          # Load existing events
          with open('assets/json/events.json', 'r') as f:
              data = json.load(f)
          
          # Load new event from temp file (safer than inline)
          with open('/tmp/augmented_event.json', 'r') as f:
              new_event = json.load(f)
          
          data['events'].append(new_event)
          
          # Save updated events
          with open('assets/json/events.json', 'w') as f:
              json.dump(data, f, indent=2)
          
          print('âœ… Event added to events.json')
          PYCODE
      
      - name: Commit published event
        if: steps.validate_pin.outputs.valid == 'true'
        run: |
          git config user.name "telegram-bot[bot]"
          git config user.email "telegram-bot[bot]@users.noreply.github.com"
          
          git add assets/json/events.json
          git commit -m "feat: publish event via Telegram PIN from @${{ steps.validate_pin.outputs.username }} [automated]"
          git push
          
          echo "âœ… Event published to production"
      
      - name: Notify on invalid PIN
        if: steps.validate_pin.outputs.valid == 'false'
        run: |
          echo "âš ï¸ Invalid PIN submission detected"
          echo "User: ${{ steps.validate_pin.outputs.username }} (ID: ${{ steps.validate_pin.outputs.user_id }})"
          echo "This is logged but no notification is sent to user (security by obscurity)"
  
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # ğŸ§ª PHASE 7: CI/CD & Quality Checks (Pull Requests)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  validate-config:
    name: âœ… Validate Config
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'pull_request' ||
      github.event.inputs.task == 'validate-config' ||
      (github.event_name == 'push' && contains(github.event.head_commit.modified, 'config.json'))
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
      
      - name: Run config validation
        run: |
          echo "âœ… Validating config.json to prevent production issues..."
          python3 scripts/validate_config.py
      
      - name: Validation summary
        run: |
          echo "## âœ… Configuration Validation" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** âœ“ Configuration is valid" >> $GITHUB_STEP_SUMMARY
          echo "**Checks performed:**" >> $GITHUB_STEP_SUMMARY
          echo "- Environment setting validation" >> $GITHUB_STEP_SUMMARY
          echo "- Required fields present" >> $GITHUB_STEP_SUMMARY
          echo "- JSON syntax validation" >> $GITHUB_STEP_SUMMARY
  
  ci-lint-test:
    name: "ğŸ§ª CI: Lint & Test"
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'pull_request' ||
      github.event.inputs.task == 'run-tests'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install flake8 black pylint pytest pytest-cov || echo "Dev tools installed"
      
      - name: Validate JSON files
        run: |
          echo "::group::Validating JSON files"
          python3 -c "import json; json.load(open('config.json'))" && echo "âœ“ config.json valid"
          python3 -c "import json; json.load(open('features.json'))" && echo "âœ“ features.json valid"
          echo "::endgroup::"
      
      - name: Run Python linting
        continue-on-error: true
        run: |
          echo "::group::Python linting"
          flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics || true
          black --check --diff src/ tests/ || true
          echo "::endgroup::"
      
      - name: JavaScript syntax check
        continue-on-error: true
        run: |
          echo "::group::JavaScript validation"
          if [ -f "assets/js/app.js" ]; then
            node -c assets/js/app.js 2>&1 || true
          fi
          echo "::endgroup::"
      
      - name: Run feature verification
        continue-on-error: true
        run: |
          echo "::group::Feature registry verification"
          if [ -f "src/modules/feature_verifier.py" ]; then
            python3 src/modules/feature_verifier.py --verbose || true
          fi
          echo "::endgroup::"
      
      - name: Discover and run tests
        continue-on-error: true
        run: |
          echo "::group::Running tests"
          if command -v pytest &> /dev/null; then
            pytest tests/ -v --tb=short --maxfail=5 || true
          else
            echo "Pytest not available"
          fi
          echo "::endgroup::"
      
      - name: CI Summary
        run: |
          echo "## ğŸ” CI Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Checks performed:**" >> $GITHUB_STEP_SUMMARY
          echo "- âœ“ JSON validation" >> $GITHUB_STEP_SUMMARY
          echo "- âœ“ Python linting" >> $GITHUB_STEP_SUMMARY
          echo "- âœ“ JavaScript syntax" >> $GITHUB_STEP_SUMMARY
          echo "- âœ“ Feature registry" >> $GITHUB_STEP_SUMMARY
          echo "- âœ“ Test execution" >> $GITHUB_STEP_SUMMARY
  
  # Job 14: PR Preview Build (from pr-preview.yml)
  pr-preview:
    name: ğŸ” Build PR Preview
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'pull_request' &&
      (github.event.inputs.enable_pr_preview != 'false')
    
    steps:
      - name: Checkout PR branch
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha }}
          fetch-depth: 2
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Fetch frontend libraries
        run: |
          python3 src/event_manager.py dependencies fetch
      
      - name: Generate Lucide icon map
        run: |
          echo "ğŸ¨ Generating Lucide icons map..."
          python3 scripts/generate_lucide_icons.py
      
      - name: Generate preview site
        env:
          ENVIRONMENT: development
        run: |
          echo "ğŸ”¨ Building preview in development mode..."
          python3 src/event_manager.py generate
          
          # Add preview notice
          PREVIEW_NOTICE="<!-- PR #${{ github.event.pull_request.number }} Preview Build -->"
          sed -i "1i $PREVIEW_NOTICE" public/index.html
      
      - name: Install Playwright for screenshots
        run: |
          pip install playwright || true
          playwright install chromium || true
      
      - name: Take screenshots
        id: screenshots
        continue-on-error: true
        run: |
          mkdir -p public/screenshots
          
          # Start local server
          cd public
          python3 -m http.server 8000 &
          SERVER_PID=$!
          sleep 3
          
          # Take screenshots
          cd ..
          python3 << 'EOF' || true
          import asyncio
          from playwright.async_api import async_playwright
          
          async def take_screenshots():
              async with async_playwright() as p:
                  browser = await p.chromium.launch()
                  
                  # Desktop
                  page = await browser.new_page(viewport={'width': 1920, 'height': 1080})
                  await page.goto('http://localhost:8000/')
                  await page.wait_for_timeout(3000)
                  await page.screenshot(path='public/screenshots/desktop.png', full_page=True)
                  
                  # Mobile
                  mobile_page = await browser.new_page(viewport={'width': 375, 'height': 667})
                  await mobile_page.goto('http://localhost:8000/')
                  await mobile_page.wait_for_timeout(3000)
                  await mobile_page.screenshot(path='public/screenshots/mobile.png', full_page=True)
                  
                  await browser.close()
          
          asyncio.run(take_screenshots())
          EOF
          
          # Stop server
          kill $SERVER_PID 2>/dev/null || true
      
      - name: Upload preview artifact
        uses: actions/upload-artifact@v4
        with:
          name: pr-${{ github.event.pull_request.number }}-preview
          path: public/
          retention-days: 90
      
      - name: Comment on PR
        uses: actions/github-script@v7
        with:
          script: |
            const prNumber = context.issue.number;
            const runId = context.runId;
            const sha = context.payload.pull_request.head.sha.substring(0, 7);
            
            const comment = `## ğŸ” PR Preview Built Successfully
            
            **Download:** [pr-${prNumber}-preview](https://github.com/${{ github.repository }}/actions/runs/${runId})
            
            ### ğŸš€ How to Test
            1. Download artifact from link above
            2. Extract zip file
            3. Open \`public/index.html\` in browser
            
            **Commit:** \`${sha}\`
            **Mode:** Development (includes demo events)
            **Valid:** 90 days
            `;
            
            github.rest.issues.createComment({
              issue_number: prNumber,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
