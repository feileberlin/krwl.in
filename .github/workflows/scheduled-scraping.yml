name: ðŸ¤– Scheduled Event & Weather Scraping

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIER 1: Core Automation - Scheduled Scraping
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# PURPOSE:
# Automatically scrape events and weather data twice daily to keep the site fresh.
# Runs at 4 AM and 4 PM Berlin time (3:00 and 15:00 UTC).
#
# WHAT THIS WORKFLOW DOES:
# 1. ðŸ“¥ Scrapes events from RSS feeds and HTML sources
# 2. ðŸŒ¤ï¸ Updates weather information
# 3. ðŸ’¾ Commits changes to pending_events.json and weather_cache.json
# 4. ðŸš€ Triggers deployment via push to main branch
#
# TRIGGERS:
# - Scheduled: 04:00 and 16:00 Berlin time (03:00 and 15:00 UTC)
# - Manual: Via "Run workflow" button
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

on:
  schedule:
    - cron: '0 3 * * *'   # 4:00 AM Berlin time - Morning update
    - cron: '0 15 * * *'  # 4:00 PM Berlin time - Afternoon update
  
  workflow_dispatch:
    inputs:
      force_scrape:
        description: 'Force re-scraping even if cached'
        type: boolean
        default: false
        required: false

permissions:
  contents: write  # Push commits (scraped data)

concurrency:
  group: "scheduled-scraping"
  cancel-in-progress: false  # Let running scrapes finish

jobs:
  scrape-events:
    name: ðŸ“¥ Scrape Events
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python environment
        uses: ./.github/actions/setup-python-env
      
      - name: Scrape events from sources
        run: |
          echo "ðŸ“¥ Scraping events from configured sources..."
          python3 src/event_manager.py scrape
          
          echo "## ðŸ“¥ Event Scraping Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Time:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
      
      - name: Check for changes
        id: check_changes
        run: |
          git diff --exit-code assets/json/pending_events.json || echo "changes=true" >> $GITHUB_OUTPUT
      
      - name: Commit changes
        if: steps.check_changes.outputs.changes == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add assets/json/pending_events.json
          git commit -m "ðŸ¤– Auto-scraped events [scheduled]"
          git push
          
          echo "âœ… Scraped events committed and pushed" >> $GITHUB_STEP_SUMMARY
      
      - name: No changes
        if: steps.check_changes.outputs.changes != 'true'
        run: |
          echo "â„¹ï¸ No new events found" >> $GITHUB_STEP_SUMMARY

  scrape-weather:
    name: ðŸŒ¤ï¸ Scrape Weather
    runs-on: ubuntu-latest
    needs: scrape-events
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python environment
        uses: ./.github/actions/setup-python-env
      
      - name: Check weather enabled
        id: check_enabled
        run: |
          WEATHER_ENABLED=$(python3 -c "import json; print(json.load(open('config.json'))['weather']['enabled'])")
          echo "enabled=$WEATHER_ENABLED" >> $GITHUB_OUTPUT
          
          if [ "$WEATHER_ENABLED" = "False" ]; then
            echo "â„¹ï¸ Weather scraping is disabled in config.json" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Scrape weather data
        if: steps.check_enabled.outputs.enabled == 'True'
        run: |
          echo "ðŸŒ¤ï¸ Scraping weather data..."
          
          FORCE_FLAG=""
          if [ "${{ github.event.inputs.force_scrape }}" = "true" ]; then
            FORCE_FLAG="--force"
          fi
          
          python3 src/event_manager.py scrape-weather $FORCE_FLAG
          
          echo "## ðŸŒ¤ï¸ Weather Scraping Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Time:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
      
      - name: Check for changes
        if: steps.check_enabled.outputs.enabled == 'True'
        id: check_changes
        run: |
          git diff --exit-code assets/json/weather_cache.json || echo "changes=true" >> $GITHUB_OUTPUT
      
      - name: Commit changes
        if: steps.check_enabled.outputs.enabled == 'True' && steps.check_changes.outputs.changes == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add assets/json/weather_cache.json
          git commit -m "ðŸŒ¤ï¸ Auto-scraped weather [scheduled]"
          git push
          
          echo "âœ… Weather data committed and pushed" >> $GITHUB_STEP_SUMMARY
      
      - name: No changes
        if: steps.check_enabled.outputs.enabled == 'True' && steps.check_changes.outputs.changes != 'true'
        run: |
          echo "â„¹ï¸ Weather data unchanged" >> $GITHUB_STEP_SUMMARY
